{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "785f1b76",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9e18c8",
   "metadata": {},
   "source": [
    "#### Run the following cells before navigating through the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f385fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env SM_FRAMEWORK=tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb71323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional Code to reset GPU\n",
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "print(device)\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bae851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "import warnings\n",
    "\n",
    "def function_that_warns():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    function_that_warns()  # this will not show a warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fe0712",
   "metadata": {},
   "outputs": [],
   "source": [
    "from patchify import patchify\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import glob\n",
    "import cv2\n",
    "from patchify import patchify, unpatchify\n",
    "import seaborn as sns\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87d8515",
   "metadata": {},
   "source": [
    "## Training Phase # 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1af14c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inititate Unet using Segmentation Library\n",
    "import segmentation_models as sm\n",
    "from segmentation_models import Unet\n",
    "BACKBONE = 'vgg16'\n",
    "model = sm.Unet(BACKBONE, encoder_weights='imagenet')\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264dceec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating Images and masks path and deleting an images whose masks didnt exist\n",
    "count = 0\n",
    "train_ids_paths=[]\n",
    "train_masks_path=[]\n",
    "\n",
    "# Change the path to the image database !!\n",
    "base_path = ['mcoustat/TRAIN_1','mcoustat/TRAIN_2','mcoustat/TRAIN_3']\n",
    "\n",
    "for base in base_path:\n",
    "    total_maps= os.listdir(base)\n",
    "    with tf.device('/gpu:0'):\n",
    "      for i in total_maps:\n",
    "        t = sorted(glob.glob(os.path.join(base, i, 'images', '*.png')))\n",
    "        m = sorted(glob.glob(os.path.join(base, i, 'labels','Undefined', '*.png')))\n",
    "        total_imgs=[]\n",
    "        total_masks=[]\n",
    "\n",
    "        for item in t:\n",
    "            t1=item.split('/')\n",
    "            total_imgs.append(t1[-1])\n",
    "\n",
    "        for item in m:\n",
    "            m1=item.split('/')\n",
    "            total_masks.append(m1[-1]) \n",
    "\n",
    "        list_difference = []\n",
    "        for item in total_imgs:\n",
    "            if item not in total_masks:\n",
    "                list_difference.append(item)\n",
    "\n",
    "        for item in list_difference:\n",
    "            toRemove= os.path.join(base, i, 'images', item)\n",
    "            t.remove(toRemove)\n",
    "\n",
    "\n",
    "        if len(t) == len(m):\n",
    "            train_ids_paths +=t\n",
    "            train_masks_path += m\n",
    "        else:\n",
    "            print( 'number of images',len(t), i) \n",
    "            print( 'number of masks',len(m), i)\n",
    "    print(len(train_ids_paths), len(train_masks_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f09965f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print Total Images and masks\n",
    "print(len(train_ids_paths), len(train_masks_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914202d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Images and masks and creating tensors respectively\n",
    "\n",
    "from tqdm import tqdm\n",
    "Masks=[]\n",
    "Images=[]  \n",
    "count = 0 \n",
    "with tf.device('/gpu:0'):     \n",
    "  for img_path,mask_path in tqdm(zip(train_ids_paths, train_masks_path),total=len(train_ids_paths),position=0, leave=False):\n",
    "    img = Image.open(img_path)\n",
    "    Images.append(np.array(img))\n",
    "    mask= cv2.imread(mask_path,2)\n",
    "    mask= np.array(mask)\n",
    "    mask = np.expand_dims(mask,-1)\n",
    "    mask[mask>0]=1\n",
    "    Masks.append(mask)\n",
    "    count = count +1\n",
    "print(len(Images), len(Masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d353575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Images and masks into numpy array\n",
    "Images=np.array(Images)\n",
    "Masks=np.array(Masks)\n",
    "Images.shape, Masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9816981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling images and masks to get rid of overfitting\n",
    "from sklearn.utils import shuffle\n",
    "Images, Masks=shuffle(Images, Masks, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d2473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display 10 images and respective maps\n",
    "count = 0\n",
    "for i in range(len(Images)):\n",
    "  if count < 5:\n",
    "      fig = plt.figure(figsize=(10, 7))\n",
    "      rows,columns=1,2\n",
    "      fig.add_subplot(rows, columns, 1)\n",
    "      toShow=(1)*4  \n",
    "      # showing image\n",
    "      plt.imshow(Images[i])\n",
    "      plt.axis('off')\n",
    "      plt.title(\"Image\")\n",
    "\n",
    "      # Adds a subplot at the 2nd position\n",
    "      fig.add_subplot(rows, columns, 2)\n",
    "      plt.imshow(Masks[i][:,:,0], cmap='gray')\n",
    "      plt.axis('off')\n",
    "      plt.title(\"Mask\")\n",
    "  count +=1\n",
    "\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adf9f7c",
   "metadata": {},
   "source": [
    "#### Selecting Data for Train and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3901978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating copy for images and masks\n",
    "Images_1 = Images.copy()\n",
    "Masks_1 = Masks.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb0d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of 34000 images , select 14000 images for testing\n",
    "test_Images=Images_1[20000:30000, :,:,:]\n",
    "test_Masks= Masks_1[20000:30000, :,:,:]\n",
    "\n",
    "# To check result the number of selected images should be thousand, because sometimes GPU error comes when using 14000 images.\n",
    "# If GPU error comes in line 25 use following lines\n",
    "\n",
    "# test_Images=Images_1[20000:21000, :,:,:]\n",
    "# test_Masks= Masks_1[20000:21000, :,:,:]\n",
    "\n",
    "test_Images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704fb55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of 34000 images , select 20,000 images for training\n",
    "Images =Images[0:15000, :,:,:]\n",
    "Masks=Masks[0:15000, :,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4bd831",
   "metadata": {},
   "outputs": [],
   "source": [
    "Masks.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c1919e",
   "metadata": {},
   "source": [
    "### Cross Validation with 5 k-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927471bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation: dividing data into 5 folds.\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "kf = KFold(n_splits = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a8a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating 5 models base on cross validation sets. Save models in folder saved_models\n",
    "VALIDATION_ACCURACY = []\n",
    "VALIDAITON_LOSS = []\n",
    "\n",
    "save_dir = 'saved_models_28/'\n",
    "fold_var = 1\n",
    "count=0\n",
    "for train_index, val_index in kf.split(Images,Masks):\n",
    "    training_data = Images[train_index]\n",
    "    validation_data = Images[val_index]\n",
    "\n",
    "    training_mask = Masks[train_index]\n",
    "    validation_mask = Masks [val_index]\n",
    "    \n",
    "    model = sm.Unet(BACKBONE, encoder_weights='imagenet')\n",
    "    model.compile(optimizer='adam',loss ='binary_crossentropy', metrics=['accuracy'])\n",
    "    model_name= 'model_'+str(fold_var)+'.h5'\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+model_name, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks = [\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2),\n",
    "              tf.keras.callbacks.TensorBoard(log_dir=\"logs\"),checkpoint\n",
    "        ]\n",
    "\n",
    "    history = model.fit(x=training_data, y = training_mask, batch_size=32, epochs=3, verbose = 1, validation_data=(validation_data, validation_mask),callbacks=callbacks)\t\n",
    "    model.load_weights(\"saved_models_28/model_\"+str(fold_var)+\".h5\")\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    results = model.evaluate(validation_data,validation_mask)\n",
    "    results = dict(zip(model.metrics_names,results))\n",
    "    VALIDATION_ACCURACY.append(results['accuracy'])\n",
    "    VALIDAITON_LOSS.append(results['loss'])\n",
    "    tf.keras.backend.clear_session()\n",
    "    fold_var += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d8a9b1",
   "metadata": {},
   "source": [
    "##### Print the accuracy and loss of the cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a25611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Accuracy for 5 models\n",
    "VALIDATION_ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba5ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Loss for 5 models\n",
    "VALIDAITON_LOSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e4a003",
   "metadata": {},
   "source": [
    "### Calculate IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f117438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell only if test size is small. otherwise it will give error. This cell works fine for test images equal to 1000\n",
    "model = tf.keras.models.load_model('saved_models_28/model_1.h5')\n",
    "\n",
    "test_pred = model.predict(test_Images, verbose=1)\n",
    "test_pred_threshold = test_pred > 0.5\n",
    "\n",
    "IOU_keras=tf.keras.metrics.MeanIoU(num_classes= 2)\n",
    "IOU_keras.update_state(test_Masks, test_pred_threshold)\n",
    "print('IOU of the base model is ',(IOU_keras.result().numpy()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef09ff6a",
   "metadata": {},
   "source": [
    "### Calculate Precision And Recall and Display output prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04619bb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('saved_models_28/model_1.h5')\n",
    "test_pred = model.predict(test_Images, verbose=1)\n",
    "test_pred_threshold = test_pred > 0.5\n",
    "\n",
    "Y_pred= test_pred_threshold.astype(np.uint16)\n",
    "Y_val = test_Masks\n",
    "Y_pred1= Y_pred.reshape(-1,1)\n",
    "Y_val1= Y_val.reshape(-1,1)\n",
    "np.unique(Y_val)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(Y_val1, Y_pred1)\n",
    "print(cf_matrix)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), cmap=\"Reds\", annot=True, fmt = '.2%', square=1,   linewidth=2.)\n",
    "TP=cf_matrix[1][1]\n",
    "FP=cf_matrix[0][1]\n",
    "FN=cf_matrix[1][0]\n",
    "TN=cf_matrix[0][0]\n",
    "\n",
    "print(\"TN: \",TN,\" FP: \",FP,\" TP: \",TP,\" FN: \",FN)\n",
    "precision = (TP/(TP+FP))*100\n",
    "recall = (TP/(TP+FN))*100\n",
    "\n",
    "\n",
    "\n",
    "print (\"precision : \", precision , 'recall: ', recall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2841c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display the first 10 images\n",
    "count = 0\n",
    "for i in range(len(test_Images)):\n",
    "  fig = plt.figure(figsize=(10, 7))\n",
    "  rows,columns=1,3\n",
    "  fig.add_subplot(rows, columns, 1)\n",
    "  toShow=(1)*4  \n",
    "  # showing image\n",
    "  plt.imshow(test_Images[i])\n",
    "  plt.axis('off')\n",
    "  plt.title(\"Image\")\n",
    "  \n",
    "    \n",
    "  # Adds a subplot at the 2nd position\n",
    "  fig.add_subplot(rows, columns, 2)\n",
    "  plt.imshow(test_Masks[i][:,:,0])\n",
    "  plt.axis('off')\n",
    "  plt.title(\"Actual Mask\")\n",
    "\n",
    "  fig.add_subplot(rows, columns, 3)\n",
    "  plt.imshow(test_pred_threshold[i][:,:,0])\n",
    "  plt.axis('off')\n",
    "  plt.title(\"Predicted Mask\")\n",
    "  count = count+1\n",
    "  if count ==10:\n",
    "     break\n",
    "        \n",
    "## ajouter une validation colorimétrique?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b70ba9",
   "metadata": {},
   "source": [
    "For example, we obtained: \n",
    "\n",
    "precision :  80.60307147076196 recall:  74.87873311774777"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbb87a5",
   "metadata": {},
   "source": [
    "## Optional Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9313ff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Work in progress\n",
    "\n",
    "from scipy import ndimage\n",
    "from skimage import measure, color, io\n",
    "import pandas as pd\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "from tensorflow.keras.preprocessing import image\n",
    "pd.options.display.max_columns = None\n",
    "counter=0\n",
    "\n",
    "for i in test_pred_threshold:\n",
    "    i=i.astype('uint8')\n",
    "    uniqueValues,count = np.unique(i,return_counts=True)\n",
    "    \n",
    "    kernel = np.ones((1,20), np.uint8)  # note this is a horizontal kernel\n",
    "    d_im = cv2.dilate(i[:,:,0], kernel, iterations=1)\n",
    "    e_im = cv2.erode(d_im, kernel, iterations=1) \n",
    "    label_mask,num_labels=ndimage.label(e_im)\n",
    "    num_labels\n",
    "    print(num_labels)\n",
    "    plot_comparison(i, e_im, 'e_im')\n",
    "    clusters = measure.regionprops(label_mask, i)\n",
    "    propList = ['major_axis_length',\n",
    "            'minor_axis_length',\n",
    "            'area',\n",
    "            'equivalent_diameter', #Added... verify if it works\n",
    "            'orientation', #Added, verify if it works. Angle btwn x-axis and major axis.\n",
    "            'perimeter'\n",
    "            ] \n",
    "    print(pd.DataFrame(regionprops_table(label_mask, i, properties=propList)))\n",
    "    for j in range(num_labels):\n",
    "        if (clusters[j].major_axis_length > (clusters[j].minor_axis_length)*9):\n",
    "            label_mask[tuple(clusters[j].coords.T)]=0\n",
    "        else:\n",
    "            label_mask[tuple(clusters[j].coords.T)]=1\n",
    "    \n",
    "    label_mask = image.img_to_array(label_mask, dtype='uint8')\n",
    "    label_mask[label_mask==1]= 255\n",
    "    i[i==1]= 255\n",
    "    uniqueValues,count = np.unique(label_mask,return_counts=True)\n",
    "    uniqueValues,count = np.unique(i,return_counts=True)\n",
    "    original = i.copy()\n",
    "    final = cv2.bitwise_and(i,label_mask)\n",
    "    updated[counter]=np.expand_dims(final, -1)\n",
    "    counter = counter + 1\n",
    "    \n",
    "'''\n",
    "# To Display updated patches after apply morphology\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    rows,columns=1,2\n",
    "    fig.add_subplot(rows, columns, 1)\n",
    "    toShow=(1)*4  \n",
    "    # showing image\n",
    "    plt.imshow(original, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Original\")\n",
    "\n",
    "    # Adds a subplot at the 2nd position\n",
    "    fig.add_subplot(rows, columns, 2)\n",
    "    plt.imshow(i,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Final Image\")\n",
    "    \n",
    "    counter = counter+1\n",
    "    if counter == 50:\n",
    "        break\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ad880",
   "metadata": {},
   "source": [
    "## Generating data for next phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912d6e49",
   "metadata": {},
   "source": [
    "By using the previous trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a70801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict test Images and generate data for next training phase. Save new data into folder New_Training_folder\n",
    "model = tf.keras.models.load_model('saved_models/model_1.h5')\n",
    "test_pred = model.predict(test_Images, verbose=1)\n",
    "test_pred_threshold = test_pred > 0.6\n",
    "\n",
    "# # Saving Files\n",
    "\n",
    "Imagebase = 'New_Training_Data/Maps'\n",
    "os.listdir(Imagebase )\n",
    "Maskbase = 'New_Training_Data/Masks'\n",
    "len(os.listdir(Imagebase ))\n",
    "\n",
    "count = 0\n",
    "for i in range(len(test_Images)):\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    rows,columns=1,3\n",
    "    fig.add_subplot(rows, columns, 1)\n",
    "    toShow=(1)*4  \n",
    "    \n",
    "    # showing image\n",
    "    name= 'Image_'+str(i)+'.jpg'\n",
    "    im_path = os.path.join(Imagebase, name)\n",
    "    plt.imshow(test_Images[i])\n",
    "    plt.axis('off')\n",
    "    plt.title(name)\n",
    "\n",
    "    \n",
    "    cv2.imwrite (im_path,cv2.cvtColor(test_Images[i], cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "      \n",
    "    # Adds a subplot at the 2nd position\n",
    "    fig.add_subplot(rows, columns, 2)\n",
    "    plt.imshow(test_Masks[i][:,:,0])\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Actual Mask\")\n",
    "\n",
    "    fig.add_subplot(rows, columns, 3)\n",
    "    plt.imshow(test_pred_threshold[i][:,:,0])\n",
    "    plt.axis('off')\n",
    "    name= 'Mask_'+str(i)+'.jpg'\n",
    "    plt.title(name)\n",
    "  \n",
    "    im_path = os.path.join(Maskbase, name)\n",
    "    print(im_path)\n",
    "    mask_to_save = test_pred_threshold[i][:,:,0].astype('float32')\n",
    "    mask_to_save[mask_to_save>0]=255\n",
    "    cv2.imwrite (im_path,mask_to_save)\n",
    "    count = count+5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4baee6",
   "metadata": {},
   "source": [
    "## Training Phase # 02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7bd884",
   "metadata": {},
   "source": [
    "### Reading Custom Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03fe798",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "train_ids_paths=[]\n",
    "train_masks_path=[]\n",
    "base = 'New_Training_Data'\n",
    "\n",
    "\n",
    "total_maps= os.listdir(base)\n",
    "print(total_maps)\n",
    "#print(os.listdir(base))\n",
    "with tf.device('/gpu:0'):\n",
    "    t = sorted(glob.glob(os.path.join(base, total_maps[2],'*.jpg')))\n",
    "    m = sorted(glob.glob(os.path.join(base, total_maps[1],'*.jpg')))\n",
    "    train_ids_paths +=t\n",
    "    train_masks_path += m\n",
    "print(len(train_ids_paths), len(train_masks_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d03085",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_delete = sorted(glob.glob(os.path.join(base, total_maps[0],'*.jpg')))\n",
    "len(to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a33446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "Masks=[]\n",
    "Images=[]  \n",
    "count = 0 \n",
    "with tf.device('/gpu:0'):     \n",
    "  for img_path,mask_path in tqdm(zip(train_ids_paths, train_masks_path),total=len(train_ids_paths),position=0, leave=False):\n",
    "    img = Image.open(img_path)\n",
    "    Images.append(np.array(img))\n",
    "    mask= cv2.imread(mask_path,2)\n",
    "    mask= np.array(mask)\n",
    "    mask = np.expand_dims(mask,-1)\n",
    "    mask[mask<40]=0\n",
    "    mask[mask>40]=1\n",
    "    Masks.append(mask)\n",
    "    count = count +1\n",
    "print(len(Images), len(Masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a04663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the list into a Numpy array\n",
    "Images=np.array(Images)\n",
    "Masks=np.array(Masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0136db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "Images, Masks=shuffle(Images, Masks, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08698fe",
   "metadata": {},
   "source": [
    "##### Display the first 5 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc2e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(Images)):\n",
    "  if count < 5:\n",
    "      fig = plt.figure(figsize=(10, 7))\n",
    "      rows,columns=1,2\n",
    "      fig.add_subplot(rows, columns, 1)\n",
    "      toShow=(1)*4  \n",
    "      # showing image\n",
    "      plt.imshow(Images[i])\n",
    "      plt.axis('off')\n",
    "      plt.title(\"Image\")\n",
    "\n",
    "      # Adds a subplot at the 2nd position\n",
    "      fig.add_subplot(rows, columns, 2)\n",
    "      plt.imshow(Masks[i][:,:,0], cmap='gray')\n",
    "      plt.axis('off')\n",
    "      plt.title(\"Mask\")\n",
    "  count +=1\n",
    "\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6404e2",
   "metadata": {},
   "source": [
    "##### Select some images and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce47e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Images_1 = Images.copy()\n",
    "Masks_1 = Masks.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbdfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_Images=Images_1[13000:14001, :,:,:]\n",
    "# test_Masks= Masks_1[13000:14001, :,:,:]\n",
    "\n",
    "test_Images=Images_1[9000:10000, :,:,:]\n",
    "test_Masks= Masks_1[9000:10000, :,:,:]\n",
    "\n",
    "test_Images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862e0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Images =Images[0:800, :,:,:]\n",
    "Masks=Masks[0:800, :,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eed9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "kf = KFold(n_splits = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636de7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_ACCURACY = []\n",
    "VALIDAITON_LOSS = []\n",
    "\n",
    "save_dir = 'custom_saved_models/'\n",
    "fold_var = 1\n",
    "count=0\n",
    "for train_index, val_index in kf.split(Images,Masks):\n",
    "    training_data = Images[train_index]\n",
    "    validation_data = Images[val_index]\n",
    "\n",
    "    training_mask = Masks[train_index]\n",
    "    validation_mask = Masks [val_index]\n",
    "    \n",
    "    model = sm.Unet(BACKBONE, encoder_weights='imagenet')\n",
    "    model.compile(optimizer='adam',loss ='binary_crossentropy', metrics=['accuracy'])\n",
    "    model_name= 'model_'+str(fold_var)+'.h5'\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+model_name, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks = [\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2),\n",
    "              tf.keras.callbacks.TensorBoard(log_dir=\"logs\"),checkpoint\n",
    "        ]\n",
    "\n",
    "    history = model.fit(x=training_data, y = training_mask, batch_size=32, epochs=3, verbose = 1, validation_data=(validation_data, validation_mask),callbacks=callbacks)\t\n",
    "    model.load_weights(\"custom_saved_models/model_\"+str(fold_var)+\".h5\")\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    results = model.evaluate(validation_data,validation_mask)\n",
    "    results = dict(zip(model.metrics_names,results))\n",
    "    VALIDATION_ACCURACY.append(results['accuracy'])\n",
    "    VALIDAITON_LOSS.append(results['loss'])\n",
    "    tf.keras.backend.clear_session()\n",
    "    fold_var += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afe555a",
   "metadata": {},
   "source": [
    "Print loss and accuracy in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e72ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0a1144",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDAITON_LOSS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fdf84d",
   "metadata": {},
   "source": [
    "Training Phase 2 Completed and stored in Custom_saved_model folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2122b3b5",
   "metadata": {},
   "source": [
    "## Comparing Results of Custom Trained Model vs Base Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f925df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading base model\n",
    "model = tf.keras.models.load_model('saved_models_28/model_1.h5')\n",
    "\n",
    "# Loading custom model\n",
    "model_custom = tf.keras.models.load_model('custom_saved_models/model_1.h5')\n",
    "\n",
    "\n",
    "#Prediction Using Base Model\n",
    "test_pred = model.predict(test_Images, verbose=1)\n",
    "test_pred_threshold = test_pred > 0.5\n",
    "\n",
    "#Prediction Using Custom Model\n",
    "test_pred_custom = model_custom.predict(test_Images, verbose=1)\n",
    "test_pred_threshold_custom = test_pred_custom > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cd7952",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run only if test data is equal or less than 1000 images, otherwise GPU error will come\n",
    "IOU_keras=tf.keras.metrics.MeanIoU(num_classes= 2)\n",
    "\n",
    "#IOU using Base Model\n",
    "IOU_keras.update_state(test_Masks, test_pred_threshold)\n",
    "print('IOU using BAse Model is ',(IOU_keras.result().numpy()*100))\n",
    "\n",
    "#IOU using Custom Model\n",
    "IOU_keras.update_state(test_Masks, test_pred_threshold_custom)\n",
    "print('IOU using Custome Model is ',(IOU_keras.result().numpy()*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bba05d3",
   "metadata": {},
   "source": [
    "### Precision and Recall using Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423f4b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision Recall using Base Model\n",
    "Y_pred= test_pred_threshold.astype(np.uint16)\n",
    "Y_val = test_Masks\n",
    "Y_pred1= Y_pred.reshape(-1,1)\n",
    "Y_val1= Y_val.reshape(-1,1)\n",
    "np.unique(Y_val)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(Y_val1, Y_pred1)\n",
    "print(cf_matrix)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), cmap=\"Reds\", annot=True, fmt = '.2%', square=1,   linewidth=2.)\n",
    "TP=cf_matrix[1][1]\n",
    "FP=cf_matrix[0][1]\n",
    "FN=cf_matrix[1][0]\n",
    "TN=cf_matrix[0][0]\n",
    "\n",
    "\n",
    "print(\"*\"*100)\n",
    "print(\"Base Model: Results and Statistics\")\n",
    "print(\"*\"*100)\n",
    "\n",
    "print(\"TN: \",TN,\" FP: \",FP,\" TP: \",TP,\" FN: \",FN)\n",
    "precision = (TP/(TP+FP))*100\n",
    "recall = (TP/(TP+FN))*100\n",
    "print (\"precision : \", precision , 'recall: ', recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be714e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display the first 10 images\n",
    "count = 0\n",
    "for i in range(len(test_Images)):\n",
    "  fig = plt.figure(figsize=(10, 7))\n",
    "  rows,columns=1,3\n",
    "  fig.add_subplot(rows, columns, 1)\n",
    "  toShow=(1)*4  \n",
    "  # showing image\n",
    "  plt.imshow(test_Images[i])\n",
    "  plt.axis('off')\n",
    "  plt.title(\"Image\")\n",
    "  \n",
    "    \n",
    "  # Adds a subplot at the 2nd position\n",
    "  fig.add_subplot(rows, columns, 2)\n",
    "  plt.imshow(test_Masks[i][:,:,0])\n",
    "  plt.axis('off')\n",
    "  plt.title(\"Actual Mask\")\n",
    "\n",
    "  fig.add_subplot(rows, columns, 3)\n",
    "  plt.imshow(test_pred_threshold[i][:,:,0])\n",
    "  plt.axis('off')\n",
    "  plt.title(\"Predicted Mask\")\n",
    "  count = count+1\n",
    "  if count ==10:\n",
    "     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9283f2d7",
   "metadata": {},
   "source": [
    "### Precision and Recall using Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e24c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision Recall using Custom Model\n",
    "# Precision Recall using Base Model\n",
    "\n",
    "model = tf.keras.models.load_model('custom_saved_models/model_1.h5')\n",
    "test_pred = model.predict(test_Images, verbose=1)\n",
    "test_pred_threshold = test_pred > 0.5\n",
    "\n",
    "Y_pred= test_pred_threshold.astype(np.uint16)\n",
    "Y_val = test_Masks\n",
    "Y_pred1= Y_pred.reshape(-1,1)\n",
    "Y_val1= Y_val.reshape(-1,1)\n",
    "np.unique(Y_val)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(Y_val1, Y_pred1)\n",
    "print(cf_matrix)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), cmap=\"Reds\", annot=True, fmt = '.2%', square=1,   linewidth=2.)\n",
    "TP=cf_matrix[1][1]\n",
    "FP=cf_matrix[0][1]\n",
    "FN=cf_matrix[1][0]\n",
    "TN=cf_matrix[0][0]\n",
    "\n",
    "print(\"*\"*100)\n",
    "print(\"Custom Model: Results and Statistics\")\n",
    "print(\"*\"*100)\n",
    "\n",
    "print(\"TN: \",TN,\" FP: \",FP,\" TP: \",TP,\" FN: \",FN)\n",
    "precision = (TP/(TP+FP))*100\n",
    "recall = (TP/(TP+FN))*100\n",
    "\n",
    "\n",
    "print (\"precision : \", precision , 'recall: ', recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afb4d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display the first 10 images\n",
    "count = 0\n",
    "for i in range(len(test_Images)):\n",
    "  fig = plt.figure(figsize=(10, 7))\n",
    "  rows,columns=1,3\n",
    "  fig.add_subplot(rows, columns, 1)\n",
    "  toShow=(1)*4  \n",
    "  # showing image\n",
    "  plt.imshow(test_Images[i])\n",
    "  plt.axis('off')\n",
    "  plt.title(\"Image\")\n",
    "  \n",
    "    \n",
    "  # Adds a subplot at the 2nd position\n",
    "  fig.add_subplot(rows, columns, 2)\n",
    "  plt.imshow(test_Masks[i][:,:,0])\n",
    "  plt.axis('off')\n",
    "  plt.title(\"Actual Mask\")\n",
    "\n",
    "  fig.add_subplot(rows, columns, 3)\n",
    "  plt.imshow(test_pred_threshold[i][:,:,0])\n",
    "  plt.axis('off')\n",
    "  plt.title(\"Predicted Mask\")\n",
    "  count = count+1\n",
    "  if count ==10:\n",
    "     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948b4f89",
   "metadata": {},
   "source": [
    "## PATCHIFY CODE START HERE\n",
    "Test on one single image using the custom trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eb9a59",
   "metadata": {},
   "source": [
    "### Read Image File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dcf113",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('custom_saved_models/model_1.h5')\n",
    "#model = tf.keras.models.load_model('saved_models_28/model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3fd349",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_image = cv2.imread('OSD64/MAP_osd_64_berwickstjohn_1808.tif', 1)\n",
    "print(large_image.shape)\n",
    "large_image = cv2.cvtColor(large_image, cv2.COLOR_RGB2BGR) \n",
    "plt.imshow(large_image.astype('uint8'))\n",
    "#plt.imshow(np.real(large_image))\n",
    "Large_Image=np.array(large_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b5571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_mask = cv2.imread('OSD64/MASK_osd_64_berwickstjohn_1808.TIF', 0)\n",
    "print(large_mask.shape)\n",
    "# large_mask = cv2.cvtColor(large_image, cv2.COLOR_RGB2BGR) \n",
    "# plt.imshow(large_image.astype('uint8'))\n",
    "plt.imshow(np.real(large_mask),'gray')\n",
    "Large_mask=np.array(large_mask)\n",
    "Large_mask=np.expand_dims(Large_mask, axis=-1)\n",
    "print(Large_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7595037d",
   "metadata": {},
   "source": [
    "### Create Container to hold Image for proper step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2042cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('original imag shape',Large_Image.shape)\n",
    "remainderW =  (Large_Image.shape[0] - 256) % 256\n",
    "remainderH =  (Large_Image.shape[1] - 256) % 256\n",
    "\n",
    "if remainderW != 0:\n",
    "    width= Large_Image.shape[0] -remainderW +256\n",
    "else:\n",
    "    width = Large_Image.shape[0]\n",
    "\n",
    "if remainderH != 0:\n",
    "    height= Large_Image.shape[1] -remainderH +256\n",
    "else:\n",
    "    height = Large_Image.shape[1]\n",
    "    \n",
    "print(width , height )\n",
    "\n",
    "container = np.zeros((width, height,3), dtype=int)\n",
    "container.shape\n",
    "container[0:Large_Image.shape[0], 0:Large_Image.shape[1],:] = Large_Image[0:Large_Image.shape[0],0:Large_Image.shape[1],:]\n",
    "plt.imshow(container)\n",
    "print('New image shape', container.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38aa196f",
   "metadata": {},
   "source": [
    "### Create Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e75ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "patches= patchify(container, (256 ,256,3),step=256)\n",
    "patches.shape\n",
    "patches1=patches.reshape(patches.shape[0]*patches.shape[1]*patches.shape[2], 256,256, 3)\n",
    "patches1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18d1d57",
   "metadata": {},
   "source": [
    "### Perform Prediction on Patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650b1bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(patches1, verbose=1)\n",
    "test_pred_threshold_03 = test_pred > 0.3\n",
    "test_pred_threshold_04 = test_pred > 0.4\n",
    "test_pred_threshold_05 = test_pred > 0.5\n",
    "test_pred_threshold_06 = test_pred > 0.6\n",
    "test_pred_threshold_07 = test_pred > 0.7\n",
    "test_pred_threshold_08 = test_pred > 0.8\n",
    "test_pred_threshold_09 = test_pred > 0.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dd7fad",
   "metadata": {},
   "source": [
    "### Final Changing - Consensus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f2a58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred= np.zeros((1,55050240))\n",
    "pred3 = test_pred_threshold_03.reshape(1,-1)\n",
    "pred4 = test_pred_threshold_04.reshape(1,-1)\n",
    "pred5 = test_pred_threshold_05.reshape(1,-1)\n",
    "pred6 = test_pred_threshold_06.reshape(1,-1)\n",
    "pred7 = test_pred_threshold_07.reshape(1,-1)\n",
    "pred8 = test_pred_threshold_08.reshape(1,-1)\n",
    "pred9 = test_pred_threshold_09.reshape(1,-1)\n",
    "flag_on=0\n",
    "flag_off=0\n",
    "\n",
    "for i in range(len(pred3[0])):\n",
    "    flag_on=0\n",
    "    flag_off=0\n",
    "    for j in range(3,10):\n",
    "        test_pred=locals()['pred'+str(j)]\n",
    "        if (test_pred[0][i] == True):\n",
    "            flag_on+=1\n",
    "        else:\n",
    "            flag_off+=1\n",
    "    if (flag_on>flag_off+2):\n",
    "        # cela a été décidé un peu au \"pif\" ... peut-être cela peut être revu ou justifié.\n",
    "        \n",
    "        final_pred[0][i]=1\n",
    "    else:\n",
    "        final_pred[0][i]=0\n",
    "final_pred=final_pred.reshape((840, 256, 256, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a882f94",
   "metadata": {},
   "source": [
    "### Merge Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0206e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_threshold=final_pred\n",
    "#print(test_pred_threshold.shape , patches1.shape)\n",
    "merge_patches= patches1.reshape(patches.shape[0],patches.shape[1],patches.shape[2], 256,256, 3)\n",
    "merge_mask = test_pred_threshold.reshape(patches.shape[0],patches.shape[1],patches.shape[2], 256,256, 1)\n",
    "merge_patches=unpatchify(merge_patches,container.shape)\n",
    "merge_masks=unpatchify(merge_mask,(container.shape[0],container.shape[1],1))\n",
    "merge_masks = merge_masks.astype(int)\n",
    "merge_masks[merge_masks==1]=255\n",
    "np.unique(merge_masks)\n",
    "#plt.imshow(merge_masks, 'gray')\n",
    "print(merge_masks.shape)\n",
    "merge_masks = merge_masks[0:Large_Image.shape[0], 0:Large_Image.shape[1],:]\n",
    "print(merge_masks.shape, Large_Image.shape)\n",
    "plt.imshow(merge_masks, 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab57bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_masks[merge_masks>40]=255\n",
    "merge_masks[merge_masks<40]=0\n",
    "gt_path='OSD64'\n",
    "img='MASK_osd_64_berwickstjohn_1808'\n",
    "name ='Consensus_2 '+img+'_new_model_pred_'+str(i+1)+'.png'\n",
    "im_path = os.path.join(gt_path, name)\n",
    "print(im_path)\n",
    "cv2.imwrite (im_path,merge_masks)\n",
    "#test_pred = model.predict(patches1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4077e6",
   "metadata": {},
   "source": [
    "### Calculate Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450cbc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Stats\n",
    "\n",
    "Y_pred= merge_masks\n",
    "Y_val = Large_mask\n",
    "Y_pred[Y_pred>0]=1\n",
    "Y_val[Y_val>0]=1\n",
    "Y_pred1= Y_pred.reshape(-1,1)\n",
    "Y_val1= Y_val.reshape(-1,1)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(Y_val1, Y_pred1)\n",
    "TP=cf_matrix[1][1]\n",
    "FP=cf_matrix[0][1]\n",
    "FN=cf_matrix[1][0]\n",
    "TN=cf_matrix[0][0]\n",
    "\n",
    "print(\"TN: \",TN,\" FP: \",FP,\" TP: \",TP,\" FN: \",FN)\n",
    "precision = (TP/(TP+FP))*100\n",
    "recall = (TP/(TP+FN))*100\n",
    "\n",
    "\n",
    "print (\"precision : \", precision , 'recall: ', recall)\n",
    "    \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982d9960",
   "metadata": {},
   "source": [
    "### PATCHIFY CODE END HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SM_FRAMEWORK=tf.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-11 14:00:28.624405: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\n"
     ]
    }
   ],
   "source": [
    "%env SM_FRAMEWORK=tf.keras\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "import warnings\n",
    "\n",
    "def function_that_warns():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    function_that_warns()  # this will not show a warning\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import glob\n",
    "import cv2\n",
    "from patchify import patchify, unpatchify\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import jaccard_score, precision_recall_fscore_support\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace with your path\n",
    "save_dir = '/home/alexis/workspace/DATA/ROY/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINE TUNING FOR ROY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose a model with the right path\n",
    "#model = tf.keras.models.load_model('/home/alexis/workspace/notebook/models/model_1.h5')\n",
    "#model = tf.keras.models.load_model('/home/alexis/workspace/notebook/models/model_1_cus.h5')\n",
    "model = tf.keras.models.load_model('/home/alexis/workspace/DATA/EM/EM_model_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained UNet model\n",
    "pretrained_model = model\n",
    "\n",
    "# Replace the final layer with a new layer that predicts building locations\n",
    "x = pretrained_model.layers[-2].output\n",
    "x = Conv2D(1, (1, 1), activation='sigmoid')(x)\n",
    "fine_tuned_model = Model(pretrained_model.input, x)\n",
    "\n",
    "# Freeze some of the pre-trained layers\n",
    "for layer in fine_tuned_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model with a suitable loss function and optimizer\n",
    "fine_tuned_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data from path_in into training and validation sets\n",
    "# Creating Images and masks path and deleting images whose masks didnt exist\n",
    "count = 0\n",
    "train_ids_paths=[]\n",
    "train_masks_path=[]\n",
    "base = '/home/alexis/workspace/DATA/ROY/TRAINING_DATA'\n",
    "\n",
    "total_maps= os.listdir(base)\n",
    "t = sorted(glob.glob(os.path.join(base, 'images', '*.png')))\n",
    "m = sorted(glob.glob(os.path.join(base, 'labels','0', '*.png')))\n",
    "\n",
    "print(len(t), len(m))\n",
    "\n",
    "total_imgs=[]\n",
    "total_masks=[]\n",
    "\n",
    "for item in t:\n",
    "    t1=item.split('/')\n",
    "    total_imgs.append(t1[-1])\n",
    "\n",
    "for item in m:\n",
    "    m1=item.split('/')\n",
    "    total_masks.append(m1[-1]) \n",
    "\n",
    "list_difference = []\n",
    "for item in total_imgs:\n",
    "    if item not in total_masks:\n",
    "        list_difference.append(item)\n",
    "\n",
    "for item in list_difference:\n",
    "    toRemove= os.path.join(base, 'images', item)\n",
    "    t.remove(toRemove)\n",
    "\n",
    "if len(t) == len(m):\n",
    "    train_ids_paths +=t\n",
    "    train_masks_path += m\n",
    "else:\n",
    "    print( 'number of images',len(t), i) \n",
    "    print( 'number of masks',len(m), i)\n",
    "print(len(train_ids_paths), len(train_masks_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Images and masks and creating tensors respectively\n",
    "Masks=[]\n",
    "Images=[]  \n",
    "count = 0 \n",
    "with tf.device('/gpu:0'):     \n",
    "  for img_path,mask_path in tqdm(zip(train_ids_paths, train_masks_path),total=len(train_ids_paths),position=0, leave=False):\n",
    "    img = Image.open(img_path)\n",
    "    Images.append(np.array(img))\n",
    "    mask= cv2.imread(mask_path,2)\n",
    "    mask= np.array(mask)\n",
    "    mask = np.expand_dims(mask,-1)\n",
    "    mask[mask>0]=1\n",
    "    Masks.append(mask)\n",
    "    count = count +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Images and masks into numpy array\n",
    "Images=np.array(Images)\n",
    "Masks=np.array(Masks)\n",
    "print(Images.shape, Masks.shape)\n",
    "\n",
    "#Shuffling images and masks to get rid of overfitting\n",
    "from sklearn.utils import shuffle\n",
    "Images, Masks=shuffle(Images, Masks, random_state=42)\n",
    "\n",
    "#Display 10 images and respective maps\n",
    "count = 0\n",
    "for i in range(len(Images)):\n",
    "  if count < 5:\n",
    "      fig = plt.figure(figsize=(10, 7))\n",
    "      rows,columns=1,2\n",
    "      fig.add_subplot(rows, columns, 1)\n",
    "      toShow=(1)*4  \n",
    "      # showing image\n",
    "      plt.imshow(Images[i])\n",
    "      plt.axis('off')\n",
    "      plt.title(\"Image\")\n",
    "\n",
    "      #Adds a subplot at the 2nd position\n",
    "      fig.add_subplot(rows, columns, 2)\n",
    "      plt.imshow(Masks[i][:,:,0], cmap='gray')\n",
    "      plt.axis('off')\n",
    "      plt.title(\"Mask\")\n",
    "  count +=1\n",
    "\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "kf = KFold(n_splits = 3)\n",
    "VALIDATION_ACCURACY = []\n",
    "VALIDATION_LOSS = []\n",
    "\n",
    "fold_var = 1\n",
    "count=0\n",
    "\n",
    "for train_index, val_index in kf.split(Images,Masks):\n",
    "    training_data = Images[train_index]\n",
    "    validation_data = Images[val_index]\n",
    "\n",
    "    training_mask = Masks[train_index]\n",
    "    validation_mask = Masks [val_index]\n",
    "    \n",
    "    model = fine_tuned_model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model_name= 'model_ROY'+str(fold_var)+'.h5'\n",
    "    \n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+\"ROY_model_\"+str(fold_var)+\".h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks = [\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2),\n",
    "              tf.keras.callbacks.TensorBoard(log_dir=\"logs\"),checkpoint\n",
    "        ]\n",
    "    \n",
    "    history = model.fit(x=training_data, y = training_mask, batch_size=64, epochs=10, verbose = 0, validation_data=(validation_data, validation_mask),callbacks=callbacks)\t\n",
    "    model.load_weights(save_dir+\"ROY_model_\"+str(fold_var)+\".h5\")\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    results = model.evaluate(validation_data,validation_mask)\n",
    "    results = dict(zip(model.metrics_names,results))\n",
    "    VALIDATION_ACCURACY.append(results['accuracy'])\n",
    "    VALIDATION_LOSS.append(results['loss'])\n",
    "    tf.keras.backend.clear_session()\n",
    "    fold_var += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPLY TO PREDICT IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "gt_folder = '/home/alexis/workspace/DATA/ROY/TEST_DATA/labels/0/'\n",
    "\n",
    "def calculate_metrics(pred, gt):\n",
    "    # Binarize the masks\n",
    "    gt[gt > 0] = 1\n",
    "    pred[pred > 0] = 1\n",
    "\n",
    "    # Compute precision, recall, and F1 score\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(gt.ravel(), pred.ravel(), average='binary')\n",
    "    \n",
    "    # Compute IoU\n",
    "    IoU = jaccard_score(gt.ravel(), pred.ravel(), average='binary')\n",
    "    \n",
    "    return precision, recall, f1_score, IoU\n",
    "\n",
    "# define 9 thresholds:\n",
    "threshold_values = [0.01, 0.012, 0.014, 0.016, 0.018, 0.020, 0.022, 0.024, 0.026]\n",
    "\n",
    "# Load the model\n",
    "model = load_model(save_dir + \"ROY_model_2.h5\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREDICT IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images\n",
    "images = '/home/alexis/workspace/DATA/ROY/ROY_SPLIT_Low/images'\n",
    "output = '/home/alexis/workspace/DATA/ROY/ROY_SPLIT_Low/preds/'\n",
    "\n",
    "for img in tqdm(os.listdir(images)):\n",
    "    if img.endswith(\".TIF\"):\n",
    "        #print('predicting image: ', img)\n",
    "        # check that the image has not already been processed by checking whether the output file exists\n",
    "        if os.path.isfile(os.path.join(output, img)):\n",
    "            continue\n",
    "        # Read the image\n",
    "        large_image = cv2.imread(os.path.join(images,img),cv2.IMREAD_COLOR)\n",
    "        #print(\"Original image shape: \",large_image.shape)\n",
    "        \n",
    "        # #Uncomment to show the image in original color converting from BGR to RGB\n",
    "        # plt.imshow(cv2.cvtColor(large_image, cv2.COLOR_BGR2RGB))\n",
    "        # plt.show()\n",
    "        \n",
    "        Large_Image=np.array(large_image)\n",
    "        large_mask = cv2.imread(os.path.join(images,img), 0)\n",
    "        if large_mask is None:\n",
    "            print(f\"Cannot read mask for image {img}\")\n",
    "            continue\n",
    "        Large_mask=np.array(large_mask)\n",
    "        Large_mask=np.expand_dims(Large_mask, axis=-1)\n",
    "        #print(\"Mask shape: \",Large_mask.shape)\n",
    "\n",
    "        remainderW =  (Large_Image.shape[0] - 256) % 256\n",
    "        remainderH =  (Large_Image.shape[1] - 256) % 256\n",
    "\n",
    "        if remainderW != 0:\n",
    "            width= Large_Image.shape[0] -remainderW +256\n",
    "        else:\n",
    "            width = Large_Image.shape[0]\n",
    "\n",
    "        if remainderH != 0:\n",
    "            height= Large_Image.shape[1] -remainderH +256\n",
    "        else:\n",
    "            height = Large_Image.shape[1]\n",
    "            \n",
    "        container = np.zeros((width, height,3), dtype=int)\n",
    "        container.shape\n",
    "        container[0:Large_Image.shape[0], 0:Large_Image.shape[1],:] = Large_Image[0:Large_Image.shape[0],0:Large_Image.shape[1],:]\n",
    "        #print('New image shape', container.shape)\n",
    "\n",
    "        patches= patchify(container, (256 ,256,3),step=256)\n",
    "        #print('Patches shape: ',patches.shape)\n",
    "        patches1=patches.reshape(patches.shape[0]*patches.shape[1]*patches.shape[2], 256,256, 3)\n",
    "        #print('Patches1 shape: ',patches1.shape)\n",
    "\n",
    "        pred = model.predict(patches1, verbose=0) # type: ignore\n",
    "\n",
    "        # Threshold predictions\n",
    "        pred_thresholds = [pred > t for t in threshold_values]\n",
    "\n",
    "        total_pixels = large_image.shape[0] * large_image.shape[1]\n",
    "        final_pred = np.zeros((1, total_pixels))\n",
    "\n",
    "        num_patches_x = container.shape[1] // 256\n",
    "        num_patches_y = container.shape[0] // 256\n",
    "        num_patches = num_patches_x * num_patches_y\n",
    "\n",
    "        # Stack the thresholded predictions along a new axis\n",
    "        stacked_preds = np.stack([t.ravel() for t in pred_thresholds], axis=0)\n",
    "\n",
    "        # Sum the True values along the new axis and compare the sum to the threshold\n",
    "        threshold = 4 # 4 out of 9 thresholds must be True\n",
    "        final_pred = (np.sum(stacked_preds, axis=0) > threshold).astype(int)\n",
    "        final_pred = final_pred.reshape((num_patches, 256, 256))\n",
    "\n",
    "        # Merge the patches\n",
    "        test_pred_threshold=final_pred\n",
    "        merge_patches= patches1.reshape(patches.shape[0],patches.shape[1],patches.shape[2], 256,256, 3)\n",
    "        merge_mask = test_pred_threshold.reshape(patches.shape[0],patches.shape[1],patches.shape[2], 256,256, 1)\n",
    "        merge_patches=unpatchify(merge_patches,container.shape)\n",
    "        merge_masks=unpatchify(merge_mask,(container.shape[0],container.shape[1],1))\n",
    "        merge_masks = merge_masks.astype(int)\n",
    "        merge_masks[merge_masks==1]=255\n",
    "        np.unique(merge_masks)\n",
    "        \n",
    "        #print(merge_masks.shape)\n",
    "        merge_masks = merge_masks[0:Large_Image.shape[0], 0:Large_Image.shape[1],:]\n",
    "\n",
    "        merge_masks[merge_masks>40]=255\n",
    "        merge_masks[merge_masks<40]=0\n",
    "\n",
    "        # write the image as a tiff\n",
    "        cv2.imwrite(os.path.join(output, img), merge_masks)\n",
    "\n",
    "        # also write the image as a plain jpeg with the orignal image in background and the mask in bright blue\n",
    "        # Ensure merge_masks is a 2D boolean array\n",
    "        merge_masks = merge_masks.squeeze()  # Remove any extra dimensions\n",
    "        merge_masks = merge_masks > 128  # Convert to boolean array\n",
    "\n",
    "        # Create an RGBA mask (bright blue for the mask, transparent elsewhere)\n",
    "        rgba_mask = np.zeros((merge_masks.shape[0], merge_masks.shape[1], 4), dtype=np.uint8)\n",
    "        rgba_mask[merge_masks, :3] = [255, 0, 0]  # Bright blue color\n",
    "        rgba_mask[merge_masks, 3] = 255  # Full opacity for the mask\n",
    "\n",
    "        rgba_mask_image = Image.fromarray(rgba_mask)\n",
    "\n",
    "        # Load the original image and convert to RGBA\n",
    "        image = Image.fromarray(large_image).convert(\"RGBA\")\n",
    "\n",
    "        # Overlay RGBA mask onto the original image\n",
    "        image.paste(rgba_mask_image, (0, 0), rgba_mask_image)\n",
    "\n",
    "        # Convert to RGB and save\n",
    "        final_image = image.convert(\"RGB\")\n",
    "        output_filename = img.replace('.TIF', '.jpg').replace('.tif', '.jpg')\n",
    "\n",
    "        output_path = os.path.join(output, output_filename)\n",
    "        final_image.save(output_path)\n",
    "        print(f\"Saved composite image to {output_path}\")\n",
    "\n",
    "        # Display the final image\n",
    "        plt.imshow(final_image)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHECK THRESHOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images\n",
    "image_test = '/home/alexis/workspace/DATA/ROY/ROY_SPLIT_High/images/'\n",
    "mask_test = '/home/alexis/workspace/DATA/ROY/ROY_SPLIT_High/labels/0/'\n",
    "output_test = '/home/alexis/workspace/DATA/ROY/ROY_SPLIT_High/test/'\n",
    "gt_folder = '/home/alexis/workspace/DATA/ROY/ROY_SPLIT_High/labels/0/'\n",
    "\n",
    "# load the predicted masks\n",
    "preds = '/home/alexis/workspace/DATA/ROY/ROY_SPLIT_High/preds/'\n",
    "preds_list = []\n",
    "for img in os.listdir(preds):\n",
    "    if img.endswith(\".tif\") or img.endswith(\".TIF\"):\n",
    "        preds_list.append(img)\n",
    "\n",
    "# load the ground truth masks\n",
    "gt_list = []\n",
    "for img in os.listdir(gt_folder):\n",
    "    if img.endswith(\".tif\") or img.endswith(\".TIF\"):\n",
    "        gt_list.append(img)\n",
    "\n",
    "# only keep the images that are in both folders\n",
    "preds_list = [x for x in preds_list if x in gt_list]\n",
    "gt_list = [x for x in gt_list if x in preds_list]\n",
    "\n",
    "print('Number of predicted masks: ', len(preds_list))\n",
    "print('Number of ground truth masks: ', len(gt_list))\n",
    "\n",
    "metrics_results = {img: {} for img in preds_list if img.endswith(\".tif\") or img.endswith(\".TIF\")}\n",
    "\n",
    "for img in preds_list:\n",
    "    if img.endswith(\".tif\") or img.endswith(\".TIF\"):\n",
    "        print('checking image: ', img)\n",
    "        large_image = cv2.imread(os.path.join(image_test,img),cv2.IMREAD_COLOR)\n",
    "        #print(\"Original image shape: \",large_image.shape)\n",
    "        \n",
    "        # Uncomment to show the image in original color converting from BGR to RGB\n",
    "        #plt.imshow(cv2.cvtColor(large_image, cv2.COLOR_BGR2RGB))\n",
    "        #plt.show()\n",
    "        \n",
    "        Large_Image=np.array(large_image)\n",
    "        large_mask = cv2.imread(os.path.join(image_test,img), 0)\n",
    "        if large_mask is None:\n",
    "            print(f\"Cannot read mask for image {img}\")\n",
    "            continue\n",
    "        Large_mask=np.array(large_mask)\n",
    "        Large_mask=np.expand_dims(Large_mask, axis=-1)\n",
    "        #print(\"Mask shape: \",Large_mask.shape)\n",
    "\n",
    "        remainderW =  (Large_Image.shape[0] - 256) % 256\n",
    "        remainderH =  (Large_Image.shape[1] - 256) % 256\n",
    "\n",
    "        if remainderW != 0:\n",
    "            width= Large_Image.shape[0] -remainderW +256\n",
    "        else:\n",
    "            width = Large_Image.shape[0]\n",
    "\n",
    "        if remainderH != 0:\n",
    "            height= Large_Image.shape[1] -remainderH +256\n",
    "        else:\n",
    "            height = Large_Image.shape[1]\n",
    "            \n",
    "        container = np.zeros((width, height,3), dtype=int)\n",
    "        container.shape\n",
    "        container[0:Large_Image.shape[0], 0:Large_Image.shape[1],:] = Large_Image[0:Large_Image.shape[0],0:Large_Image.shape[1],:]\n",
    "        #print('New image shape', container.shape)\n",
    "\n",
    "        patches= patchify(container, (256 ,256,3),step=256)\n",
    "        #print('Patches shape: ',patches.shape)\n",
    "        patches1=patches.reshape(patches.shape[0]*patches.shape[1]*patches.shape[2], 256,256, 3)\n",
    "        #print('Patches1 shape: ',patches1.shape)\n",
    "\n",
    "        test_pred = model.predict(patches1, verbose=0)\n",
    "\n",
    "        # Threshold predictions\n",
    "        test_pred_thresholds = [test_pred > t for t in threshold_values]\n",
    "\n",
    "        total_pixels = large_image.shape[0] * large_image.shape[1]\n",
    "        final_pred = np.zeros((1, total_pixels))\n",
    "\n",
    "        num_patches_x = large_image.shape[1] // 256\n",
    "        num_patches_y = large_image.shape[0] // 256\n",
    "        num_patches = num_patches_x * num_patches_y\n",
    "\n",
    "        # Stack the thresholded predictions along a new axis\n",
    "        stacked_preds = np.stack([t.ravel() for t in test_pred_thresholds], axis=0)\n",
    "\n",
    "        # find the corresponding gt mask for the image\n",
    "        gt = cv2.imread(os.path.join(gt_folder,img),2)\n",
    "\n",
    "        for idx, threshold_value in enumerate(threshold_values):\n",
    "            # Calculate metrics\n",
    "            precision, recall, f1_score, IoU = calculate_metrics(test_pred_thresholds[idx], gt)\n",
    "\n",
    "            # Store metrics in the dictionary\n",
    "            metrics_results[img][threshold_value] = {\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1_score': f1_score,\n",
    "                'IoU': IoU\n",
    "            }\n",
    "\n",
    "        # Sum the True values along the new axis and compare the sum to the threshold\n",
    "        threshold = 4 # 4 out of 9 thresholds must be True\n",
    "        final_pred = (np.sum(stacked_preds, axis=0) > threshold).astype(int)\n",
    "        final_pred = final_pred.reshape((num_patches, 256, 256, 1))\n",
    "\n",
    "        # Merge the patches\n",
    "        test_pred_threshold=final_pred\n",
    "        merge_patches= patches1.reshape(patches.shape[0],patches.shape[1],patches.shape[2], 256,256, 3)\n",
    "        merge_mask = test_pred_threshold.reshape(patches.shape[0],patches.shape[1],patches.shape[2], 256,256, 1)\n",
    "        merge_patches=unpatchify(merge_patches,container.shape)\n",
    "        merge_masks=unpatchify(merge_mask,(container.shape[0],container.shape[1],1))\n",
    "        merge_masks = merge_masks.astype(int)\n",
    "        merge_masks[merge_masks==1]=255\n",
    "        np.unique(merge_masks)\n",
    "        #print(merge_masks.shape)\n",
    "        merge_masks = merge_masks[0:Large_Image.shape[0], 0:Large_Image.shape[1],:]\n",
    "\n",
    "        merge_masks[merge_masks>40]=255\n",
    "        merge_masks[merge_masks<40]=0\n",
    "\n",
    "        # write the image\n",
    "        cv2.imwrite(output_test+img, merge_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate median F1 score and IoU for each threshold\n",
    "median_f1_scores = []\n",
    "median_IoUs = []\n",
    "median_Precision = []\n",
    "median_Recall = []\n",
    "\n",
    "\n",
    "for threshold_value in threshold_values:\n",
    "    f1_scores = [v.get(threshold_value, {}).get('f1_score', None) for v in metrics_results.values()]\n",
    "    IoUs = [v.get(threshold_value, {}).get('IoU', None) for v in metrics_results.values()]\n",
    "    Precision = [v.get(threshold_value, {}).get('precision', None) for v in metrics_results.values()]\n",
    "    Recall = [v.get(threshold_value, {}).get('recall', None) for v in metrics_results.values()]\n",
    "\n",
    "    # Filter out None values\n",
    "    f1_scores = [score for score in f1_scores if score is not None]\n",
    "    IoUs = [iou for iou in IoUs if iou is not None]\n",
    "    Precision = [precision for precision in Precision if precision is not None]\n",
    "    Recall = [recall for recall in Recall if recall is not None]\n",
    "\n",
    "    median_f1_scores.append(np.median(f1_scores))\n",
    "    median_IoUs.append(np.median(IoUs))\n",
    "    median_Precision.append(np.median(Precision))\n",
    "    median_Recall.append(np.median(Recall))\n",
    "\n",
    "# Plot the median F1 score IoU and the recall and precision for each threshold\n",
    "plt.plot(threshold_values, median_f1_scores, label='F1 score')\n",
    "plt.plot(threshold_values, median_IoUs, label='IoU')\n",
    "plt.plot(threshold_values, median_Precision, label='Precision')\n",
    "plt.plot(threshold_values, median_Recall, label='Recall')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.title('Median F1 score, IoU, Precision and Recall for each threshold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COLOR EXTRACTION for the Roy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorextraction(images_list, color_ext):\n",
    "    def extractRColor(src):\n",
    "        \"\"\"Extract the red component in an image and display it\"\"\"\n",
    "\n",
    "        src_hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # # Display the HSV image\n",
    "        # plt.imshow(cv2.cvtColor(src_hsv, cv2.COLOR_HSV2RGB))\n",
    "        # plt.title('HSV Image')\n",
    "        # plt.show()\n",
    "\n",
    "        # lower_red1 = np.array([160,40,140])\n",
    "        # upper_red1 = np.array([180,255,255])\n",
    "\n",
    "        # lower_red2 = np.array([0,40,30]) # empirically determined that 30 was the best threshold for ROY\n",
    "        # upper_red2 = np.array([12,255,255])\n",
    "\n",
    "        lower_red1 = np.array([0, 100, 100])\n",
    "        upper_red1 = np.array([10, 255, 255])\n",
    "\n",
    "        lower_red2 = np.array([160, 100, 100])\n",
    "        upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "\n",
    "        # Define the HSV range for the blue color to exclude\n",
    "        lower_blue = np.array([110, 100, 100])  # Adjust these values based on specific blue\n",
    "        upper_blue = np.array([130, 255, 255])\n",
    "\n",
    "        # Creating masks\n",
    "        mask_red1 = cv2.inRange(src_hsv, lower_red1, upper_red1)\n",
    "        mask_red2 = cv2.inRange(src_hsv, lower_red2, upper_red2)\n",
    "        mask_blue = cv2.inRange(src_hsv, lower_blue, upper_blue)\n",
    "\n",
    "        # #dilate blue mask\n",
    "        # kernel = np.ones((5,5), np.uint8)\n",
    "        # mask_blue = cv2.dilate(mask_blue, kernel, iterations=1)\n",
    "\n",
    "        # # dilate red masks\n",
    "        # kernel = np.ones((25,25), np.uint8)\n",
    "        # mask_red1 = cv2.dilate(mask_red1, kernel, iterations=1)\n",
    "        # mask_red2 = cv2.dilate(mask_red2, kernel, iterations=1)\n",
    "\n",
    "        # # show blue mask\n",
    "        # plt.imshow(mask_blue, cmap='gray')\n",
    "        # plt.title('Blue mask')\n",
    "        # plt.show()\n",
    "\n",
    "        # Combine red masks\n",
    "        mask_red = cv2.add(mask_red1, mask_red2)\n",
    "        # #show red mask\n",
    "        # plt.imshow(mask_red, cmap='gray')\n",
    "        # plt.title('Red mask')\n",
    "        # plt.show()\n",
    "\n",
    "        # Subtract blue mask from red mask\n",
    "        mask = cv2.subtract(mask_red, mask_blue)\n",
    "        # plt.imshow(mask, cmap='gray')\n",
    "        # plt.title('Mask after blue subtraction')\n",
    "        # plt.show()\n",
    "        \n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "        kernel_2 = np.ones((2,2), np.uint8)\n",
    "        kernel_hm = np.array((\n",
    "            [0, -1, 0],\n",
    "            [-1, 1, -1],\n",
    "            [0, -1, 0]), dtype=\"int\")\n",
    "\n",
    "        kernel_hm_diag = np.array((\n",
    "            [-1, 0, -1],\n",
    "            [0, 1, 0],\n",
    "            [-1, 0, -1]), dtype=\"int\")\n",
    "\n",
    "        res_hm = cv2.morphologyEx(mask, cv2.MORPH_HITMISS, kernel_hm)\n",
    "        res_hm_diag = cv2.morphologyEx(mask, cv2.MORPH_HITMISS, kernel_hm_diag)\n",
    "        \n",
    "        # # Display hit-miss results\n",
    "        # plt.imshow(res_hm, cmap='gray')\n",
    "        # plt.title('Hit-miss result (kernel_hm)')\n",
    "        # plt.show()\n",
    "\n",
    "        # plt.imshow(res_hm_diag, cmap='gray')\n",
    "        # plt.title('Hit-miss result (kernel_hm_diag)')\n",
    "        # plt.show()\n",
    "\n",
    "        mask = cv2.subtract(mask, res_hm)\n",
    "        mask = cv2.subtract(mask, res_hm_diag)\n",
    "\n",
    "        # # Display mask after hit-miss subtraction\n",
    "        # plt.imshow(mask, cmap='gray')\n",
    "        # plt.title('Mask after hit-miss subtraction')\n",
    "\n",
    "        res_hm = cv2.morphologyEx(mask, cv2.MORPH_HITMISS, kernel_hm)\n",
    "        res_hm_diag = cv2.morphologyEx(mask, cv2.MORPH_HITMISS, kernel_hm_diag)\n",
    "        \n",
    "        # # Display second hit-miss results\n",
    "        # plt.imshow(res_hm, cmap='gray')\n",
    "        # plt.title('Second hit-miss result (kernel_hm)')\n",
    "        # plt.show()\n",
    "\n",
    "        # plt.imshow(res_hm_diag, cmap='gray')\n",
    "        # plt.title('Second hit-miss result (kernel_hm_diag)')\n",
    "        # plt.show()\n",
    "\n",
    "        mask = cv2.subtract(mask, res_hm)\n",
    "        mask = cv2.subtract(mask, res_hm_diag)\n",
    "\n",
    "        # # Display mask after second hit-miss subtraction\n",
    "        # plt.imshow(mask, cmap='gray')\n",
    "        # plt.title('Mask after second hit-miss subtraction')\n",
    "        # plt.show()\n",
    "\n",
    "        lower_white = np.array([253,253,253])\n",
    "        upper_white = np.array([255,255,255])\n",
    "        src_bg = cv2.inRange(src, lower_white, upper_white)\n",
    "        \n",
    "        # # Display white background mask\n",
    "        # plt.imshow(src_bg, cmap='gray')\n",
    "        # plt.title('White background mask')\n",
    "        # plt.show()\n",
    "\n",
    "        src_final = 255 - cv2.add(255 - mask, src_bg)\n",
    "\n",
    "        # # Display the final result\n",
    "        # plt.imshow(src_final, cmap='gray')\n",
    "        # # show title with the name of the image wihtout the path\n",
    "        # plt.title('Final result for image: ' + filename.split('/')[-1].split('.')[0])\n",
    "        # plt.show()\n",
    "\n",
    "        return src_final\n",
    "\n",
    "    for filename in tqdm(images_list, total=len(images_list), position=0, leave=True):\n",
    "        filename_wo_path = filename.split('/')[-1].split('.')[0]\n",
    "        large_image = cv2.imread(filename)\n",
    "        red = extractRColor(large_image)\n",
    "        out_path = os.path.join(color_ext, filename_wo_path +'.tif')\n",
    "        cv2.imwrite(out_path, red)\n",
    "\n",
    "    return 'Colour extraction completed'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1202/1202 [10:28<00:00,  1.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Colour extraction completed'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply to images from ROY dataset\n",
    "\n",
    "images = r'/home/alexis/workspace/DATA/ROY/ROY_SPLIT'\n",
    "colour_ext = r'/home/alexis/workspace/DATA/ROY/ROY_COLOR_PREDS'\n",
    "\n",
    "images_list = glob.glob(os.path.join(images, '*.TIF'))\n",
    "images_list.sort()\n",
    "\n",
    "colorextraction(images_list, colour_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MERGE CNN AND COLOR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MERGE WITH CNN SO THAT ONLY COMPONENTS DETECTED BY THE CNN ARE MODIFIED "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_classification_path(file_path, base_preds):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    file_name_no_ext = os.path.splitext(file_name)[0]\n",
    "    return os.path.join(base_preds, file_name_no_ext)\n",
    "\n",
    "def get_color_classification_path(file_path, color_ext):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    file_name_no_ext = os.path.splitext(file_name)[0]\n",
    "    return os.path.join(color_ext, file_name_no_ext)\n",
    "\n",
    "def classification_files_exist(cnnpred_file, colorpred_file):\n",
    "    return os.path.exists(cnnpred_file) and os.path.exists(colorpred_file)\n",
    "\n",
    "def get_fusion_path(file_path, fusion_ext):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    file_name_no_ext = os.path.splitext(file_name)[0]\n",
    "    return os.path.join(fusion_ext, file_name_no_ext)\n",
    "\n",
    "def process_images(cnnpred, colorpred):\n",
    "    \"\"\"Replace connected components in base predictions with connected components from color predictions.\"\"\"\n",
    "    # Find connected components in colorpred and cnnpred\n",
    "    nb_lbl_color, lbl_color = cv2.connectedComponents(colorpred, connectivity=8)\n",
    "    nb_lbl_cnn, lbl_cnn = cv2.connectedComponents(cnnpred, connectivity=8)\n",
    "\n",
    "    # Create an empty array for the output\n",
    "    output = np.zeros_like(cnnpred)\n",
    "\n",
    "    # Iterate through the connected components in cnnpred\n",
    "    for i in range(1, nb_lbl_cnn):\n",
    "        # Get the mask for the current connected component in cnnpred\n",
    "        cnn_component_mask = (lbl_cnn == i)\n",
    "\n",
    "        # Find all the connected components in colorpred that intersect with the current connected component in cnnpred\n",
    "        color_component_labels = np.unique(lbl_color[cnn_component_mask])\n",
    "        color_component_labels = color_component_labels[color_component_labels != 0]  # Ignore the background component\n",
    "\n",
    "        # Replace the current connected component in cnnpred with the corresponding connected components from colorpred\n",
    "        for color_label in color_component_labels:\n",
    "            output[(lbl_color == color_label)] = 255\n",
    "\n",
    "    return output\n",
    "\n",
    "# version where the color extraction serves to filter CNN predictions \n",
    "def filter_images(cnnpred, colorpred):\n",
    "    \"\"\"Replace connected components in base predictions with connected components from color predictions.\"\"\"\n",
    "    # Find connected components in colorpred and cnnpred\n",
    "    nb_lbl_color, lbl_color = cv2.connectedComponents(colorpred, connectivity=8)\n",
    "    nb_lbl_cnn, lbl_cnn = cv2.connectedComponents(cnnpred, connectivity=8)\n",
    "\n",
    "    # Create an empty array for the output\n",
    "    output = np.zeros_like(cnnpred)\n",
    "\n",
    "    # Iterate through the connected components in cnnpred\n",
    "    for i in range(1, nb_lbl_cnn):\n",
    "        # Get the mask for the current connected component in cnnpred\n",
    "        cnn_component_mask = (lbl_cnn == i)\n",
    "\n",
    "        # Find all the connected components in cnnpred that intersect with the color component\n",
    "        color_component_labels = np.unique(lbl_color[cnn_component_mask])\n",
    "        color_component_labels = color_component_labels[color_component_labels != 0]\n",
    "\n",
    "        # Keep only the connected component in cnnpred that intersect with connected components from colorpred\n",
    "        for color_label in color_component_labels:\n",
    "            output[(lbl_cnn == i)] = 255\n",
    "        \n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paths\n",
    "images = r'/home/alexis/workspace/DATA/ROY/ROY_SPLIT/'\n",
    "base_preds = r'/home/alexis/workspace/DATA/ROY/ROY_SPLIT_PREDS'\n",
    "color_ext = r'/home/alexis/workspace/DATA/ROY/ROY_COLOR_PREDS'\n",
    "fusion_ext = r'/home/alexis/workspace/DATA/ROY/ROY_FUSION'\n",
    "\n",
    "# Get the list of image files\n",
    "images_list = glob.glob(os.path.join(base_preds, '*.TIF'))\n",
    "images_list.sort()\n",
    "\n",
    "new_image_list = []\n",
    "\n",
    "# Filter image list by checking the existence of classification files\n",
    "for file_path in images_list:\n",
    "    colorpred_file = get_color_classification_path(file_path, color_ext) + \".tif\"\n",
    "    cnnpred_file = get_base_classification_path(file_path, base_preds) + \".TIF\"\n",
    "\n",
    "    if classification_files_exist(cnnpred_file, colorpred_file):\n",
    "        new_image_list.append(get_base_classification_path(file_path, base_preds))\n",
    "\n",
    "print(len(new_image_list), \"images have predictions and colour extraction\")\n",
    "\n",
    "# Processing\n",
    "for base_pred_file in tqdm(new_image_list, total=len(new_image_list), position=0, leave=True):\n",
    "    try:\n",
    "        # extract filename from base_pred_file wihtout path and extension\n",
    "        base_fusion_file = get_fusion_path(base_pred_file, fusion_ext)\n",
    "        base_color_file = get_color_classification_path(base_pred_file, color_ext)\n",
    "\n",
    "        #if the file has already been processed, skip it\n",
    "        #if os.path.exists(base_fusion_file + '.tif'):\n",
    "            #continue\n",
    "\n",
    "        cnnpred = Image.open(base_pred_file + '.TIF')            \n",
    "        cnnpred = cnnpred.convert('L')\n",
    "        cnnpred = np.array(cnnpred)\n",
    "        colorpred = cv2.imread(base_color_file + '.tif',0)\n",
    "        src_final = process_images(cnnpred, colorpred)\n",
    "        \n",
    "        # Saving\n",
    "        base_pred_file = os.path.basename(base_pred_file)\n",
    "        cv2.imwrite(base_fusion_file + '.tif', src_final)\n",
    "\n",
    "        # also write the image as a plain jpeg with the orignal image in background and the mask in bright blue\n",
    "        # Ensure merge_masks is a 2D boolean array\n",
    "        src_final = src_final.squeeze()  # Remove any extra dimensions\n",
    "        src_final = src_final > 128  # Convert to boolean array\n",
    "\n",
    "        # Create an RGBA mask (bright pink for the mask, transparent elsewhere)\n",
    "        rgba_mask = np.zeros((src_final.shape[0], src_final.shape[1], 4), dtype=np.uint8)\n",
    "        rgba_mask[src_final, :3] = [200,30,180] # Bright pink color\n",
    "        rgba_mask[src_final, 3] = 255  # Full opacity for the mask\n",
    "\n",
    "        rgba_mask_image = Image.fromarray(rgba_mask)\n",
    "\n",
    "        # Load the original image and convert to RGBA\n",
    "        image = Image.fromarray(cv2.imread(os.path.join(images, base_pred_file+'.TIF')))\n",
    "\n",
    "        # Overlay RGBA mask onto the original image\n",
    "        image.paste(rgba_mask_image, (0, 0), rgba_mask_image)\n",
    "\n",
    "        # Convert to RGB and save\n",
    "        final_image = image.convert(\"RGB\")\n",
    "        output_filename = base_pred_file.replace('.TIF', '.jpg').replace('.tif', '.jpg')\n",
    "\n",
    "        output_path = os.path.join(fusion_ext, output_filename+'.jpg')\n",
    "        final_image.save(output_path)\n",
    "        print(f\"Saved composite image to {output_path}\")\n",
    "\n",
    "        # Display the final image\n",
    "        plt.imshow(final_image)\n",
    "        plt.axis('off')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Error processing file: \" + base_pred_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) VERSION WHERE COLOR SERVES TO FILTER CNN OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1641 images have predictions and colour extraction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1641 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1641/1641 [2:29:11<00:00,  5.45s/it]  \n"
     ]
    }
   ],
   "source": [
    "#Define paths\n",
    "images = r'/home/alexis/workspace/DATA/ROY/ROY_SPLIT/'\n",
    "base_preds = r'/home/alexis/workspace/DATA/ROY/ROY_SPLIT_PREDS'\n",
    "color_ext = r'/home/alexis/workspace/DATA/ROY/ROY_COLOR_PREDS'\n",
    "fusion_ext = r'/home/alexis/workspace/DATA/ROY/ROY_FUSION'\n",
    "\n",
    "# Get the list of image files\n",
    "images_list = glob.glob(os.path.join(base_preds, '*.TIF'))\n",
    "images_list.sort()\n",
    "\n",
    "new_image_list = []\n",
    "\n",
    "# Filter image list by checking the existence of classification files\n",
    "for file_path in images_list:\n",
    "    colorpred_file = get_color_classification_path(file_path, color_ext) + \".tif\"\n",
    "    cnnpred_file = get_base_classification_path(file_path, base_preds) + \".TIF\"\n",
    "\n",
    "    if classification_files_exist(cnnpred_file, colorpred_file):\n",
    "        new_image_list.append(get_base_classification_path(file_path, base_preds))\n",
    "\n",
    "print(len(new_image_list), \"images have predictions and colour extraction\")\n",
    "\n",
    "# Processing\n",
    "for base_pred_file in tqdm(new_image_list, total=len(new_image_list), position=0, leave=True):\n",
    "    try:\n",
    "        # extract filename from base_pred_file wihtout path and extension\n",
    "        base_fusion_file = get_fusion_path(base_pred_file, fusion_ext)\n",
    "        base_color_file = get_color_classification_path(base_pred_file, color_ext)\n",
    "\n",
    "        # if the file has already been processed, skip it\n",
    "        if os.path.exists(base_fusion_file + '.tif'):\n",
    "            continue\n",
    "\n",
    "        cnnpred = Image.open(base_pred_file + '.TIF')            \n",
    "        cnnpred = cnnpred.convert('L')\n",
    "        cnnpred = np.array(cnnpred)\n",
    "        colorpred = cv2.imread(base_color_file + '.tif',0)\n",
    "        src_final = filter_images(cnnpred, colorpred)\n",
    "        \n",
    "        # Saving\n",
    "        base_pred_file = os.path.basename(base_pred_file)\n",
    "        cv2.imwrite(base_fusion_file + '.tif', src_final)\n",
    "\n",
    "        # # also write the image as a plain jpeg with the orignal image in background and the mask in bright blue\n",
    "        # # Ensure merge_masks is a 2D boolean array\n",
    "        # src_final = src_final.squeeze()  # Remove any extra dimensions\n",
    "        # src_final = src_final > 128  # Convert to boolean array\n",
    "\n",
    "        # # Create an RGBA mask (bright pink for the mask, transparent elsewhere)\n",
    "        # rgba_mask = np.zeros((src_final.shape[0], src_final.shape[1], 4), dtype=np.uint8)\n",
    "        # rgba_mask[src_final, :3] = [200,30,180] # Bright pink color\n",
    "        # rgba_mask[src_final, 3] = 255  # Full opacity for the mask\n",
    "\n",
    "        # rgba_mask_image = Image.fromarray(rgba_mask)\n",
    "\n",
    "        # # Load the original image and convert to RGBA\n",
    "        # image = Image.fromarray(cv2.imread(os.path.join(images, base_pred_file+'.TIF')))\n",
    "\n",
    "        # # Overlay RGBA mask onto the original image\n",
    "        # image.paste(rgba_mask_image, (0, 0), rgba_mask_image)\n",
    "\n",
    "        # # Convert to RGB and save\n",
    "        # final_image = image.convert(\"RGB\")\n",
    "        # output_filename = base_pred_file.replace('.tif', '.jpeg').replace('.TIF', '.jpeg')\n",
    "\n",
    "        # output_path = os.path.join(fusion_ext, output_filename)\n",
    "        # final_image.save(output_path)\n",
    "        # print(f\"Saved composite image to {output_path}\")\n",
    "\n",
    "        # # Display the final image\n",
    "        # plt.imshow(final_image)\n",
    "        # plt.axis('off')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Error processing file: \" + base_pred_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "Show 3 random images with their predicted masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 4, figsize=(20, 15))\n",
    "img_folder = r'/home/alexis/workspace/DATA/ROY/ROY_SPLIT/'\n",
    "fusion_folder = r'/home/alexis/workspace/DATA/ROY/ROY_FUSION/'\n",
    "preds_folder = r'/home/alexis/workspace/DATA/ROY/ROY_SPLIT_PREDS/'\n",
    "color_folder = r'/home/alexis/workspace/DATA/ROY/ROY_COLOR_PREDS/'\n",
    "\n",
    "img_list = glob.glob(os.path.join(img_folder, '*.TIF'))\n",
    "img_list.sort()\n",
    "\n",
    "preds_list = glob.glob(os.path.join(preds_folder, '*.TIF'))\n",
    "preds_list.sort()\n",
    "\n",
    "color_list = glob.glob(os.path.join(color_folder, '*.tif'))\n",
    "color_list.sort()\n",
    "\n",
    "fusion_list = glob.glob(os.path.join(fusion_folder, '*.tif'))\n",
    "fusion_list.sort()\n",
    "\n",
    "for i in range(3):\n",
    "    random_index = np.random.randint(0, len(img_list))\n",
    "    img = Image.open(os.path.join(img_folder,img_list[random_index]))\n",
    "    pred = Image.open(os.path.join(preds_folder,preds_list[random_index]))\n",
    "    color = Image.open(os.path.join(color_folder,color_list[random_index]))\n",
    "    fusion = Image.open(os.path.join(fusion_folder,fusion_list[random_index]))\n",
    "    \n",
    "    # convert to 8-bit format\n",
    "    pred = pred.convert('L')\n",
    "    fusion = fusion.convert('L')\n",
    "    color = color.convert('L')\n",
    "\n",
    "    # convert to numpy arrays\n",
    "    pred = np.array(pred)\n",
    "    fusion = np.array(fusion)\n",
    "    color = np.array(color)\n",
    "    \n",
    "    # show the orginal image\n",
    "    # keep only the filenmae without the path and extension\n",
    "    img_name = os.path.basename(img_list[random_index])\n",
    "    ax[i, 0].imshow(img)\n",
    "    ax[i, 0].set_title('{}'.format(img_name))\n",
    "    ax[i, 0].axis('off')\n",
    "\n",
    "    # show the predicted mask\n",
    "    pred_name = os.path.basename(preds_list[random_index])\n",
    "    ax[i, 1].imshow(pred, cmap='gray')\n",
    "    ax[i, 1].set_title('pred for: {}'.format(pred_name))\n",
    "    ax[i, 1].axis('off')\n",
    "\n",
    "    # show the color mask\n",
    "    color_name = os.path.basename(color_list[random_index])\n",
    "    ax[i, 2].imshow(color, cmap='gray')\n",
    "    ax[i, 2].set_title('color for: {}'.format(color_name))\n",
    "    ax[i, 2].axis('off')\n",
    "    \n",
    "    # show the fusion mask\n",
    "    fusion_name = os.path.basename(fusion_list[random_index])\n",
    "    ax[i, 3].imshow(fusion, cmap='gray')\n",
    "    ax[i, 3].set_title('fusion for {}'.format(fusion_name))\n",
    "    ax[i, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REMOVE BLANK IMAGES AND CLEAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if any original image is entirely white or black\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "img_folder = r'/home/alexis/workspace/DATA/ROY/ROY_SPLIT/'\n",
    "img_list = glob.glob(os.path.join(img_folder, '*.TIF'))\n",
    "img_list.sort()\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "white_images = []\n",
    "\n",
    "def process_image(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    img_np = np.array(img)\n",
    "\n",
    "    # if the image contains only values over 249\n",
    "    if np.all(img_np > 240):\n",
    "        #print(\"Image {} is all white or black\".format(img_path))\n",
    "        img_name = os.path.basename(img_path)\n",
    "        return img_np, img_name\n",
    "    return None, None\n",
    "\n",
    "def parallel_check_images(img_list, num_workers=4):\n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        results = list(tqdm(executor.map(process_image, img_list), total=len(img_list)))\n",
    "\n",
    "    for img, img_name in results:\n",
    "        if img is not None and img_name is not None:\n",
    "            #add image to list\n",
    "            white_images.append(img_name)\n",
    "\n",
    "parallel_check_images(img_list)\n",
    "\n",
    "\n",
    "img_folder = r'/home/alexis/workspace/DATA/ROY/ROY_SPLIT/'\n",
    "white_folder = r'/home/alexis/workspace/DATA/ROY/ROY_SPLIT_WHITE/'\n",
    "\n",
    "for img in tqdm(white_images):\n",
    "    shutil.move(img_folder + img, white_folder + img)\n",
    "\n",
    "fusion_folder = r'/home/alexis/workspace/DATA/ROY/GEOPRED_10_04_2023/'\n",
    "img_list = glob.glob(os.path.join(white_folder, '*.TIF'))\n",
    "img_list.sort()\n",
    "\n",
    "# delete from the fusion folder the images that are the white_folder\n",
    "\n",
    "for img in tqdm(img_list):\n",
    "    img_name = os.path.basename(img)\n",
    "    #replace .TIF with .tif\n",
    "    img_name = img_name.replace('.TIF', '_geo.tif')\n",
    "    os.remove(fusion_folder + img_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MEASURE ACCURACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply color extraction and fusion to test images\n",
    "\n",
    "base_img = r'/home/alexis/workspace/DATA/ROY/TEST_DATA/images/'\n",
    "base_preds = r'/home/alexis/workspace/DATA/ROY/TEST_DATA/preds/'\n",
    "color_ext = r'/home/alexis/workspace/DATA/ROY/TEST_DATA/color/'\n",
    "fusion_ext = r'/home/alexis/workspace/DATA/ROY/TEST_DATA/fusion/'\n",
    "\n",
    "images_list = glob.glob(os.path.join(base_img, '*.tif'))\n",
    "images_list.sort()\n",
    "\n",
    "images_list = images_list\n",
    "\n",
    "colorextraction(images_list, color_ext)\n",
    "\n",
    "new_image_list = []\n",
    "\n",
    "# Filter image list by checking the existence of classification files\n",
    "for file_path in images_list:\n",
    "    colorpred_file = get_color_classification_path(file_path, color_ext)+'.tif'\n",
    "    cnnpred_file = get_base_classification_path(file_path, base_preds)+'.tif'\n",
    "\n",
    "    if classification_files_exist(cnnpred_file, colorpred_file):\n",
    "        new_image_list.append(get_base_classification_path(file_path, base_preds))\n",
    "\n",
    "print(len(new_image_list), \"images have predictions and colour extraction\")\n",
    "\n",
    "# Processing\n",
    "for base_pred_file in tqdm(new_image_list, total=len(new_image_list), position=0, leave=True):\n",
    "    try:\n",
    "        # extract filename from base_pred_file wihtout path and extension\n",
    "        base_color_file = get_color_classification_path(base_pred_file, color_ext)\n",
    "        cnnpred = Image.open(base_pred_file + '.tif')\n",
    "        # convert to 8-bit format\n",
    "        cnnpred = cnnpred.convert('L')\n",
    "        cnnpred = np.array(cnnpred)\n",
    "        colorpred = cv2.imread(base_color_file + '.tif',0)\n",
    "        src_final = process_images(cnnpred, colorpred)\n",
    "\n",
    "        # Saving\n",
    "        base_pred_file = os.path.basename(base_pred_file)\n",
    "        cv2.imwrite(os.path.join(fusion_ext, base_pred_file + '.tif'), src_final)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Error processing file: \" + base_pred_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score, precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from PIL import Image\n",
    "\n",
    "# load the predicted masks\n",
    "preds = '/home/alexis/workspace/DATA/ROY/TEST_DATA/fusion/'\n",
    "preds_list = []\n",
    "for img in os.listdir(preds):\n",
    "    if img.endswith(\".tif\"):\n",
    "        preds_list.append(img)\n",
    "\n",
    "# load the ground truth masks\n",
    "gt_folder = '/home/alexis/workspace/DATA/ROY/TEST_DATA/labels/0/'\n",
    "gt_list = []\n",
    "for img in os.listdir(gt_folder):\n",
    "    if img.endswith(\".tif\"):\n",
    "        gt_list.append(img)\n",
    "\n",
    "# only keep the images that are in both folders\n",
    "preds_list = [x for x in preds_list if x in gt_list]\n",
    "gt_list = [x for x in gt_list if x in preds_list]\n",
    "\n",
    "print('Number of predicted masks: ', len(preds_list))\n",
    "print('Number of ground truth masks: ', len(gt_list))\n",
    "\n",
    "# create dictionaries to store the precision, recall, F1 score and IoU, with image names as keys\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "f1_score_dict = {}\n",
    "iou_dict = {}\n",
    "\n",
    "for i in range(len(preds_list)):\n",
    "    pred = Image.open(os.path.join(preds,preds_list[i]))\n",
    "    gt = Image.open(os.path.join(gt_folder,gt_list[i]))\n",
    "    \n",
    "    # convert to 8-bit format\n",
    "    pred = pred.convert('L')\n",
    "    gt = gt.convert('L')\n",
    "    \n",
    "    # convert to numpy arrays\n",
    "    pred = np.array(pred)\n",
    "    gt = np.array(gt)\n",
    "    \n",
    "    # in the gt mask all values above 0 are considered as 1\n",
    "    gt[gt > 0] = 1\n",
    "    pred[pred > 0] = 1\n",
    "\n",
    "    # compute precision, recall, and F1 score, for 0 and 1 values\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(gt.ravel(), pred.ravel())\n",
    "    precision_dict[preds_list[i]] = precision\n",
    "    recall_dict[preds_list[i]] = recall\n",
    "    f1_score_dict[preds_list[i]] = f1_score\n",
    "\n",
    "    # compute IoU\n",
    "    IoU = jaccard_score(gt.ravel(), pred.ravel(), average=None)\n",
    "    iou_dict[preds_list[i]] = IoU\n",
    "\n",
    "# print the mean precision, recall, IoU, and F1 score\n",
    "print('Mean precision: ', np.mean(list(precision_dict.values())))\n",
    "print('Mean recall: ', np.mean(list(recall_dict.values())))\n",
    "print('Mean IoU: ', np.mean(list(iou_dict.values())))\n",
    "print('Mean F1 score: ', np.mean(list(f1_score_dict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #order the dictionaries in decreasing order of values\n",
    "# precision_dict = dict(sorted(precision_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "# recall_dict = dict(sorted(recall_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "# f1_score_dict = dict(sorted(f1_score_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "# iou_dict = dict(sorted(iou_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# set dir for original images\n",
    "img_folder = r'/home/alexis/workspace/DATA/ROY/TEST_DATA/images/'\n",
    "col_folder = r'/home/alexis/workspace/DATA/ROY/TEST_DATA/color/'\n",
    "preds_folder = r'/home/alexis/workspace/DATA/ROY/TEST_DATA/preds/'\n",
    "fusion_folder = r'/home/alexis/workspace/DATA/ROY/TEST_DATA/fusion/'\n",
    "\n",
    "# for each key, plot on the same figure, the precision, recall, F1 score, and IoU, only iterating over the first 5 keys\n",
    "for key in list(precision_dict.keys())[:5]:\n",
    "    #if precision_dict[key] < 0.5:\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    fig.suptitle('{}'.format(key))\n",
    "\n",
    "    #load the original image\n",
    "    print(os.path.join(img_folder,key))\n",
    "    img = Image.open(os.path.join(img_folder,key))\n",
    "    img = np.array(img)\n",
    "    \n",
    "    # load the predicted mask\n",
    "    pred = Image.open(os.path.join(preds_folder,key))\n",
    "    pred = pred.convert('L')\n",
    "    pred = np.array(pred)\n",
    "    pred[pred > 0] = 1\n",
    "\n",
    "    # load the color pred\n",
    "    color = Image.open(os.path.join(col_folder,key))\n",
    "    color = color.convert('L')\n",
    "    color = np.array(color)\n",
    "    color[color > 0] = 1\n",
    "\n",
    "    # load the ground truth mask\n",
    "    gt = Image.open(os.path.join(gt_folder,key))\n",
    "    gt = gt.convert('L')\n",
    "    gt = np.array(gt)\n",
    "    gt[gt > 0] = 1\n",
    "\n",
    "    # load the fusion mask\n",
    "    fusion = Image.open(os.path.join(fusion_folder,key))\n",
    "    fusion = fusion.convert('L')\n",
    "    fusion = np.array(fusion)\n",
    "    fusion[fusion > 0] = 1\n",
    "    \n",
    "    \n",
    "    # show the predicted mask\n",
    "    ax[0].imshow(pred, cmap='gray')\n",
    "    ax[0].set_title('PRED, precision: {}'.format(precision_dict[key]))\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    # show the color mask\n",
    "    ax[1].imshow(fusion, cmap='gray')\n",
    "    ax[1].set_title('FUSION, recall: {}'.format(recall_dict[key]))\n",
    "    ax[1].axis('off')\n",
    "\n",
    "    \n",
    "    # show the ground truth mask\n",
    "    ax[2].imshow(gt, cmap='gray')\n",
    "    ax[2].set_title('GT')\n",
    "    ax[2].axis('off')\n",
    "\n",
    "    # show the original image\n",
    "    ax[3].imshow(img, cmap='gray')\n",
    "    ax[3].set_title('original image')\n",
    "    ax[3].axis('off')\n",
    "    \n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "# # show the names of the images with the lower recall\n",
    "# for i in range(len(recall_list)): \n",
    "#     if recall_list[i] < 0.1:\n",
    "#         print(preds_list[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation\n",
    "\n",
    "Show 3 random images with their predicted masks, and the corresponding ground truth masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(15, 15))\n",
    "img_folder = '/home/alexis/workspace/DATA/ROY/TEST_DATA/images/'\n",
    "for i in range(3):\n",
    "    #random_index = np.random.randint(0, len(preds_list))\n",
    "    random_index = 30+i\n",
    "    pred = Image.open(os.path.join(preds,gt_list[random_index]))\n",
    "    gt = Image.open(os.path.join(gt_folder,gt_list[random_index]))\n",
    "    img = Image.open(os.path.join(img_folder,gt_list[random_index]))\n",
    "    \n",
    "    # convert to 8-bit format\n",
    "    pred = pred.convert('L')\n",
    "    gt = gt.convert('L')\n",
    "    \n",
    "    # convert to numpy arrays\n",
    "    pred = np.array(pred)\n",
    "    gt = np.array(gt)\n",
    "    \n",
    "    # show the orginal image\n",
    "    ax[i, 0].imshow(img)\n",
    "    ax[i, 0].set_title('Original image for file {}'.format(preds_list[random_index]))\n",
    "    ax[i, 0].axis('off')\n",
    "\n",
    "    # show the original mask\n",
    "    ax[i, 1].imshow(pred, cmap='gray')\n",
    "    ax[i, 1].set_title('Predicted mask for file {}'.format(preds_list[random_index]))\n",
    "    ax[i, 1].axis('off')\n",
    "    \n",
    "    # show the ground truth mask\n",
    "    ax[i, 2].imshow(gt, cmap='gray')\n",
    "    ax[i, 2].set_title('Ground truth mask for file {}'.format(gt_list[random_index]))\n",
    "    ax[i, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect lines in image prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../opencv4/build/install_folder/lib:../opencv4/build/install_folder/lib:../opencv4/build/install_folder/lib:../opencv4/build/install_folder/lib:../opencv4/build/install_folder/lib:../opencv4/build/install_folder/lib:../opencv4/build/install_folder/lib:/usr/local/cuda/lib64\n",
      "1606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1606/1606 [12:33<00:00,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB processed images:  1606 / 1606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import glob\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Set environment variable to access opencv static libraries\n",
    "cv_lib_dir = '../opencv4/build/install_folder/lib:'\n",
    "if os.getenv('LD_LIBRARY_PATH') == None:\n",
    "    os.environ['LD_LIBRARY_PATH'] = cv_lib_dir\n",
    "else:\n",
    "    os.environ['LD_LIBRARY_PATH'] = cv_lib_dir + os.getenv('LD_LIBRARY_PATH')\n",
    "\n",
    "print(os.getenv('LD_LIBRARY_PATH'))\n",
    "\n",
    "base_classif = '/home/alexis/workspace/DATA/ROY/ROY_FUSION'\n",
    "images_list = glob.glob(os.path.join(base_classif, '*.tif'))\n",
    "images_list.sort()\n",
    "# images_list = images_list[388:]\n",
    "print(len(images_list))\n",
    "\n",
    "base_rep_flash = \"/home/alexis/workspace/notebook/yfaula_app/build/\"\n",
    "base_results_flash = \"/home/alexis/workspace/notebook/yfaula_app/images/\"\n",
    "\n",
    "if not os.path.exists(base_results_flash):\n",
    "    os.makedirs(base_results_flash)\n",
    "\n",
    "compteur = 0\n",
    "\n",
    "for filename in tqdm(images_list, total=len(images_list), position=0, leave=True):\n",
    "    rproc = subprocess.run([base_rep_flash + \"flash\", \"-p=\"+base_rep_flash + \"flash_default_parameters.txt\", \n",
    "                            \"--output_dir=\" + base_results_flash, filename], capture_output=True)\n",
    "    if rproc.returncode == 0:\n",
    "        compteur += 1\n",
    "    else:\n",
    "        print( 'Problem with : ', filename)\n",
    "        print(rproc.stderr)\n",
    "        \n",
    "print('NB processed images: ', compteur, '/', len(images_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1606/1606 [04:44<00:00,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB lines elimination:  1606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "base_output = '/home/alexis/workspace/DATA/ROY/FLASH_ELIMINATION/'\n",
    "\n",
    "\n",
    "if not os.path.exists(base_output):\n",
    "    os.makedirs(base_output)\n",
    "\n",
    "compteur=0\n",
    "\n",
    "for filename in tqdm(images_list, total=len(images_list), position=0, leave=True):\n",
    "    im_flash_path = base_results_flash + filename.split('/')[-1].split('.')[0] + \"_flashlines.png\"\n",
    "    \n",
    "    pred = cv2.imread(filename, 0)\n",
    "    \n",
    "    if os.path.exists(im_flash_path):\n",
    "        lines = cv2.imread(im_flash_path, 0)\n",
    "        \n",
    "        ### POST PROCESSING OF LINE DETECTION : 2 possibilities :\n",
    "        ## change the if condition in order to choose a solution (False or True)\n",
    "        ## 1) (SOLUTION PROPOSAL 1) enlarge the detection to the adjacent pixels\n",
    "        if False:\n",
    "            nb_lbl, lbl = cv2.connectedComponents(pred,connectivity=8)\n",
    "\n",
    "            #pred_merge_and  = cv2.bitwise_and(pred, cnnpred)\n",
    "\n",
    "            counter_lbl = [ 0 ] * nb_lbl\n",
    "            counter_lbl_lines = [ 0 ] * nb_lbl\n",
    "\n",
    "            for i in range(lbl.shape[0]):\n",
    "                for j in range(lbl.shape[1]):\n",
    "                    if pred[i, j]:\n",
    "                        counter_lbl[lbl[i, j]] += 1\n",
    "                    if lines[i, j] and pred[i, j]:\n",
    "                        counter_lbl_lines[lbl[i, j]] += 1\n",
    "\n",
    "            for i in range(pred.shape[0]):\n",
    "                for j in range(pred.shape[1]):\n",
    "                    # between .20 and .33 because of flash mask size\n",
    "                    if pred[i, j] > 0 and counter_lbl[lbl[i, j]] > 0:\n",
    "                        pred[i, j] = 0 if counter_lbl_lines[lbl[i, j]]/counter_lbl[lbl[i, j]] > 0.25  else 255\n",
    "\n",
    "            pred_final = pred\n",
    "            \n",
    "        else:\n",
    "        ## 2) (BASIC SOLUTION) enlarge the detection with morpholgy operations\n",
    "            ker = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (6, 6)) # depends on the size of flash kernel (7, 7)\n",
    "            lines = cv2.dilate(lines, ker, iterations=1)\n",
    "            \n",
    "            mask_flash2 = cv2.bitwise_and(lines, pred)\n",
    "            pred_final = cv2.bitwise_xor(pred, mask_flash2)\n",
    "        \n",
    "        compteur+=1\n",
    "    else:\n",
    "        pred_final = pred\n",
    "\n",
    "    cv2.imwrite(base_output + filename.split('/')[-1].split('.')[0] + '.tif', pred_final)\n",
    "\n",
    "print('NB lines elimination: ', compteur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENERAL IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env SM_FRAMEWORK=tf.keras\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "import warnings\n",
    "\n",
    "def function_that_warns():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    function_that_warns()  # this will not show warnings\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import glob\n",
    "import cv2\n",
    "from patchify import patchify, unpatchify\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import jaccard_score, precision_recall_fscore_support\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your path\n",
    "save_dir = 'YOUR_PATH'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINE TUNING FOR ROY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model will be chosen accordingly. \n",
    "Please modify the path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose a model with the right path\n",
    "model = tf.keras.models.load_model('YOUR_SAVED_MODELS_PATH/model_1_cus.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained UNet model\n",
    "pretrained_model = model\n",
    "\n",
    "# Replace the final layer with a new layer that predicts building locations\n",
    "x = pretrained_model.layers[-2].output\n",
    "x = Conv2D(1, (1, 1), activation='sigmoid')(x)\n",
    "fine_tuned_model = Model(pretrained_model.input, x)\n",
    "\n",
    "# Freeze some of the pre-trained layers\n",
    "for layer in fine_tuned_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model with a suitable loss function and optimizer\n",
    "fine_tuned_model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data from path_in into training and validation sets\n",
    "# Creating Images and masks path and deleting images whose masks didnt exist\n",
    "count = 0\n",
    "train_ids_paths=[]\n",
    "train_masks_path=[]\n",
    "base = 'YOUR_PATH_TO_YOUR_TRAINING_DATA' # The data is in the form of images and labels, where labels are further divided into the relevant classes.\n",
    "\n",
    "total_maps= os.listdir(base)\n",
    "t = sorted(glob.glob(os.path.join(base, 'images', '*.png')))\n",
    "m = sorted(glob.glob(os.path.join(base, 'labels','0', '*.png')))\n",
    "\n",
    "print(len(t), len(m))\n",
    "\n",
    "total_imgs=[]\n",
    "total_masks=[]\n",
    "\n",
    "for item in t:\n",
    "    t1=item.split('/')\n",
    "    total_imgs.append(t1[-1])\n",
    "\n",
    "for item in m:\n",
    "    m1=item.split('/')\n",
    "    total_masks.append(m1[-1]) \n",
    "\n",
    "list_difference = []\n",
    "for item in total_imgs:\n",
    "    if item not in total_masks:\n",
    "        list_difference.append(item)\n",
    "\n",
    "for item in list_difference:\n",
    "    toRemove= os.path.join(base, 'images', item)\n",
    "    t.remove(toRemove)\n",
    "\n",
    "if len(t) == len(m):\n",
    "    train_ids_paths +=t\n",
    "    train_masks_path += m\n",
    "else:\n",
    "    print( 'number of images',len(t), i) \n",
    "    print( 'number of masks',len(m), i)\n",
    "print(len(train_ids_paths), len(train_masks_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Images and masks and creating tensors respectively\n",
    "Masks=[]\n",
    "Images=[]  \n",
    "count = 0 \n",
    "with tf.device('/gpu:0'):     \n",
    "  for img_path,mask_path in tqdm(zip(train_ids_paths, train_masks_path),total=len(train_ids_paths),position=0, leave=False):\n",
    "    img = Image.open(img_path)\n",
    "    Images.append(np.array(img))\n",
    "    mask= cv2.imread(mask_path,2)\n",
    "    mask= np.array(mask)\n",
    "    mask = np.expand_dims(mask,-1)\n",
    "    mask[mask>0]=1\n",
    "    Masks.append(mask)\n",
    "    count = count +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Images and masks into numpy array\n",
    "Images=np.array(Images)\n",
    "Masks=np.array(Masks)\n",
    "print(Images.shape, Masks.shape)\n",
    "\n",
    "#Shuffling images and masks to get rid of overfitting\n",
    "from sklearn.utils import shuffle\n",
    "Images, Masks=shuffle(Images, Masks, random_state=42)\n",
    "\n",
    "#Display 10 images and respective maps\n",
    "count = 0\n",
    "for i in range(len(Images)):\n",
    "  if count < 5:\n",
    "      fig = plt.figure(figsize=(10, 7))\n",
    "      rows,columns=1,2\n",
    "      fig.add_subplot(rows, columns, 1)\n",
    "      toShow=(1)*4  \n",
    "      # showing image\n",
    "      plt.imshow(Images[i])\n",
    "      plt.axis('off')\n",
    "      plt.title(\"Image\")\n",
    "\n",
    "      #Adds a subplot at the 2nd position\n",
    "      fig.add_subplot(rows, columns, 2)\n",
    "      plt.imshow(Masks[i][:,:,0], cmap='gray')\n",
    "      plt.axis('off')\n",
    "      plt.title(\"Mask\")\n",
    "  count +=1\n",
    "\n",
    "print (count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "kf = KFold(n_splits = 3)\n",
    "VALIDATION_ACCURACY = []\n",
    "VALIDATION_LOSS = []\n",
    "\n",
    "fold_var = 1\n",
    "count=0\n",
    "\n",
    "for train_index, val_index in kf.split(Images,Masks):\n",
    "    training_data = Images[train_index]\n",
    "    validation_data = Images[val_index]\n",
    "\n",
    "    training_mask = Masks[train_index]\n",
    "    validation_mask = Masks [val_index]\n",
    "    \n",
    "    model = fine_tuned_model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model_name= 'model_ROY'+str(fold_var)+'.h5'\n",
    "    \n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(save_dir+\"FINE_TUNED_model_\"+str(fold_var)+\".h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks = [\n",
    "             tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2),\n",
    "              tf.keras.callbacks.TensorBoard(log_dir=\"logs\"),checkpoint\n",
    "        ]\n",
    "    \n",
    "    history = model.fit(x=training_data, y = training_mask, batch_size=64, epochs=10, verbose = 0, validation_data=(validation_data, validation_mask),callbacks=callbacks)\t\n",
    "    model.load_weights(save_dir+\"FINE_TUNED_model_\"+str(fold_var)+\".h5\")\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    results = model.evaluate(validation_data,validation_mask)\n",
    "    results = dict(zip(model.metrics_names,results))\n",
    "    VALIDATION_ACCURACY.append(results['accuracy'])\n",
    "    VALIDATION_LOSS.append(results['loss'])\n",
    "    tf.keras.backend.clear_session()\n",
    "    fold_var += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APPLY TO PREDICT IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "gt_folder = 'YOUR_PATH_TO_YOUR_TEST_DATA'\n",
    "\n",
    "def calculate_metrics(pred, gt):\n",
    "    # Binarize the masks\n",
    "    gt[gt > 0] = 1\n",
    "    pred[pred > 0] = 1\n",
    "\n",
    "    # Compute precision, recall, and F1 score\n",
    "    precision, recall, f1_score, _ = precision_recall_fscore_support(gt.ravel(), pred.ravel(), average='binary')\n",
    "    \n",
    "    # Compute IoU\n",
    "    IoU = jaccard_score(gt.ravel(), pred.ravel(), average='binary')\n",
    "    \n",
    "    return precision, recall, f1_score, IoU\n",
    "\n",
    "# define 9 thresholds:\n",
    "threshold_values = [0.01, 0.012, 0.014, 0.016, 0.018, 0.020, 0.022, 0.024, 0.026]\n",
    "\n",
    "# Load the model\n",
    "model = load_model(save_dir + \"FINE_TUNED_model2.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
